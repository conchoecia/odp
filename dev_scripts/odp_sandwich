"""
This script uses blastp, not diamond blastp.

This script takes two species for comparison to a set of other species.
  - One of the species is the outgroup to all the other species (must be known)
  - The other species must be in the most inner clade with the other species
The species for comparison are between those two.

   STATE OF THE TREE BEFORE THIS ANALYSIS
    Species A is the outgroup, D is known to be in the most derived clade.
     _________
     |       |
     |   ____|____
     |   |   |   |
     A   B   C   D

    The analysis makes sets of genes by comparing the n x m chromosomes of A+D

   STATE OF THE TREE AFTER THIS ANALYSIS
    This analysis will help the user resolve whether B or C is the sister to
      the other species, right after A.
     ________          ________
     |   ___|___       |   ___|___
     |   |   __|__     |   |   __|__
     |   |   |   |     |   |   |   |
     A   B   C   D     A   C   B   D

         ^                 ^
         |                 C is sister to to B + D
         |
         B is sister to C + D

Requirements:
  - Only one species defined for A
  - Only one species defined for B
  - As many species as you want in for B/C. You have to interpret the results.
"""

from Bio import SeqIO
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord
from itertools import groupby
from itertools import product
import matplotlib
import math
from operator import itemgetter
import pandas as pd
import odp_functions as OdpF
import numpy as np
import statistics
import sys
import yaml
from shutil import copyfile

configfile: "config.yaml"

# check for legal config entries. Useful for finding misspelled entries
legal = ["proteins", "prot_to_loc", "genome", "minscafsize",
         "manual_breaks", "chrom_to_color", "plotorder",
         "noylines", "noxlines"]

illegal = set()
for this_axis in ["Aspecies", "Dspecies", "BCspecies"]:
    if this_axis in config:
        for this_sample in config[this_axis]:
            for key in config[this_axis][this_sample]:
                if key not in legal:
                    illegal.add(key)

if len(illegal) > 0:
    print("We found some fields in your config file that are not used by this program.")
    print("The only fields allowed for individual samples are:")
    for key in legal:
        print("  - {}".format(key))
    print("The keys that we found that are not allowed/in the list above are:")
    for key in illegal:
        print("  - {}".format(key))
    sys.exit()

#make fake breaks for later analyses
for this_axis in ["Aspecies", "Dspecies", "BCspecies"]:
    if this_axis in config:
        for this_one in config[this_axis]:
            if "manual_breaks" not in config[this_axis][this_one]:
                config[this_axis][this_one]["manual_breaks"] = []
            if "minscafsize" not in config[this_axis][this_one]:
                config[this_axis][this_one]["minscafsize"] = 5000

if "ignore_autobreaks" in config:
    raise IOError("""We do not calculate autobreaks for this script.
                  Please remove ignore_autobreaks from the config file.""")

if "ignore_Fisher" in config:
    raise IOError("""We must calculate the Fisher's exact test in this script.
                  Please remove ignore_Fisher from the config file.""")

fisher_files = []
#make the correlation plots - whole chromosomes
outfiles = OdpF.expand_avoid_matching(
    "synteny_analysis/plots/significance/wholechr_colors/{Asample}_and_{Dsample}_against_{BCsample}_fisher_chromcolor.pdf",
    Asample = config["Aspecies"], Dsample = config["Dspecies"],
    BCsample = config["BCspecies"])
fisher_files.append(list(outfiles))

## this currently doesn't work - need to trace back where the errors are from
#outfiles = OdpF.expand_avoid_matching(
#"synteny_analysis/plots/significance/breaks/{xsample}_and_{ysample}_fisher_manualbreaks.pdf",
#     xsample = config["xaxisspecies"], ysample = config["yaxisspecies"])
#fisher_files.append(list(outfiles))
fisher_files = OdpF.flatten(fisher_files)

rule all:
    input:
        # testing area
        OdpF.expand_avoid_matching(
        "synteny_analysis/plots/synteny_uncolored/{Asample}_and_{Dsample}_against_{BCsample}_synteny_manualbreaks.pdf",
            Asample = config["Aspecies"], Dsample = config["Dspecies"],
            BCsample = config["BCspecies"]),
        fisher_files,

        #OdpF.expand_avoid_matching("synteny_analysis/plots/synteny_uncolored/{xsample}_and_{ysample}_synteny_manualbreaks.pdf",
        #        xsample = config["xaxisspecies"], ysample = config["yaxisspecies"]),
        ##expand_avoid_matching_x_and_y_kwargs("synteny_analysis/dvalue_table/{xsample}_and_{ysample}_info.tsv",
        ##        xsample = config["xaxisspecies"], ysample = config["yaxisspecies"]),
        #OdpF.expand_avoid_matching("synteny_analysis/blastp_results/xsamp_to_all/{xsample}_to_all_recip.tsv",
        #                                     xsample = config["xaxisspecies"]),
        ## working on plotting for color
        #expand("synteny_analysis/prot_to_color/{colorby}_prottocolor.tsv",
        #       colorby = [x for x in config["xaxisspecies"] if "chrom_to_color" in config["xaxisspecies"][x]]),
        ## now make a config file for other odp plotting functions
        #"synteny_analysis/odp_plotting_configs/odp_plotting_configs.yaml",
        ## These need to be rewritten such that x and y do not match
        #OdpF.expand_avoid_matching(
        #    "synteny_analysis/plots/synteny_colored_by/{xsample}_and_{ysample}_coloredby_{third}_synteny_manualbreaks.pdf",
        #    xsample = config["xaxisspecies"], ysample = config["yaxisspecies"],
        #    third = [x for x in config["xaxisspecies"] if "chrom_to_color" in config["xaxisspecies"][x]]
        #    ),
        #OdpF.expand_avoid_matching(
        #    "synteny_analysis/plots/synteny_colored_by_no_missing/{xsample}_and_{ysample}_coloredby_{third}_synteny_manualbreaks.pdf",
        #    xsample = config["xaxisspecies"], ysample = config["yaxisspecies"],
        #    third = [x for x in config["xaxisspecies"] if "chrom_to_color" in config["xaxisspecies"][x]]
        #    ),


rule filter_prots_A:
    """
    Sometimes the prot file with have sequences that are not present in
     the chrom file. Make a prot file of only the proteins in the chrom file.
    """
    input:
        prots = lambda wildcards: config["Aspecies"][wildcards.Asample]["proteins"],
        chrom = lambda wildcards: config["Aspecies"][wildcards.Asample]["prot_to_loc"]
    output:
        pep = "synteny_analysis/db/Asample/{Asample}_prots.pep"
    threads: 1
    run:
        OdpF.filter_fasta_chrom(input.chrom, input.prots, output.pep)

rule filter_prots_D:
    """
    Sometimes the prot file with have sequences that are not present in
     the chrom file. Make a prot file of only the proteins in the chrom file.
    """
    input:
        prots = lambda wildcards: config["Dspecies"][wildcards.Dsample]["proteins"],
        chrom = lambda wildcards: config["Dspecies"][wildcards.Dsample]["prot_to_loc"]
    output:
        pep = "synteny_analysis/db/Dsample/{Dsample}_prots.pep"
    threads: 1
    run:
        OdpF.filter_fasta_chrom(input.chrom, input.prots, output.pep)

rule filter_prots_BC:
    """
    Sometimes the prot file with have sequences that are not present in
     the chrom file. Make a prot file of only the proteins in the chrom file.
    """
    input:
        prots = lambda wildcards: config["BCspecies"][wildcards.BCsample]["proteins"],
        chrom = lambda wildcards: config["BCspecies"][wildcards.BCsample]["prot_to_loc"]
    output:
        pep = "synteny_analysis/db/BCsample/{BCsample}_prots.pep"
    threads: 1
    run:
        OdpF.filter_fasta_chrom(input.chrom, input.prots, output.pep)

rule make_blastdb_A:
    input:
        pep =  "synteny_analysis/db/Asample/{Asample}_prots.pep"
    output:
        pdb = "synteny_analysis/db/Asample/{Asample}_prots.pep.pdb"
    threads: 1
    shell:
        """
        makeblastdb -in {input.pep} -dbtype prot
        """

rule make_blastdb_BC:
    input:
        pep =  "synteny_analysis/db/BCsample/{BCsample}_prots.pep"
    output:
        pdb = "synteny_analysis/db/BCsample/{BCsample}_prots.pep.pdb"
    threads: 1
    shell:
        """
        makeblastdb -in {input.pep} -dbtype prot
        """

rule make_blastdb_D:
    input:
        pep =  "synteny_analysis/db/Dsample/{Dsample}_prots.pep"
    output:
        pdb = "synteny_analysis/db/Dsample/{Dsample}_prots.pep.pdb"
    threads: 1
    shell:
        """
        makeblastdb -in {input.pep} -dbtype prot
        """

rule diamond_blast_A_to_D:
    input:
        Apep  = "synteny_analysis/db/Asample/{Asample}_prots.pep",
        Dprot = "synteny_analysis/db/Dsample/{Dsample}_prots.pep",
        Dpdb  = "synteny_analysis/db/Dsample/{Dsample}_prots.pep.pdb"
    output:
        blastp = "synteny_analysis/blastp_results/AtoD/{Asample}_against_{Dsample}.blastp"
    threads: workflow.cores - 1
    shell:
        """
        blastp -query {input.Apep} -db {input.Dprot} \
          -num_threads {threads} -evalue 1E-5 -outfmt 6 > {output.blastp}
        """

rule diamond_blast_D_to_A:
    input:
        Dpep = "synteny_analysis/db/Dsample/{Dsample}_prots.pep",
        Aprot = "synteny_analysis/db/Asample/{Asample}_prots.pep",
        Apdb = "synteny_analysis/db/Asample/{Asample}_prots.pep.pdb",
    output:
        blastp = "synteny_analysis/blastp_results/DtoA/{Dsample}_against_{Asample}.blastp"
    threads: workflow.cores - 1
    shell:
        """
        blastp -query {input.Dpep} -db {input.Aprot} \
          -num_threads {threads} -evalue 1E-5 -outfmt 6 > {output.blastp}
        """

rule absolute_best_from_blast_A_to_D:
    input:
        blastp = "synteny_analysis/blastp_results/AtoD/{Asample}_against_{Dsample}.blastp"
    output:
        blastp = "synteny_analysis/blastp_results/AtoDbest/{Asample}_against_{Dsample}.blastp"
    threads: 1
    shell:
        """
        awk 'BEGIN{{former = ""}} {{if ($1 != former){{print($0)}}; former=$1}}' {input.blastp} > {output.blastp}
        """

rule absolute_best_from_blast_D_to_A:
    input:
        blastp = "synteny_analysis/blastp_results/DtoA/{Dsample}_against_{Asample}.blastp"
    output:
        blastp = "synteny_analysis/blastp_results/DtoAbest/{Dsample}_against_{Asample}.blastp"
    threads: 1
    shell:
        """
        awk 'BEGIN{{former = ""}} {{if ($1 != former){{print($0)}}; former=$1}}' {input.blastp} > {output.blastp}
        """

rule reciprocal_best_hits_A_and_D:
    """
    finds the reciprocal best hits.
    reports it in the form of the blastp results from A -> D search
    """
    input:
        AtoDblastp = "synteny_analysis/blastp_results/AtoDbest/{Asample}_against_{Dsample}.blastp",
        DtoAblastp = "synteny_analysis/blastp_results/DtoAbest/{Dsample}_against_{Asample}.blastp"
    output:
        AtoDblastp = "synteny_analysis/blastp_results/AD_reciprocal_best/{Asample}_and_{Dsample}_recip.blastp"
    threads: 1
    run:
        OdpF.reciprocal_best_hits(input.AtoDblastp,
                                  input.DtoAblastp,
                                  output.AtoDblastp)

rule reciprocal_best_AD_numbered:
    input:
        AtoDblastp = "synteny_analysis/blastp_results/AD_reciprocal_best/{Asample}_and_{Dsample}_recip.blastp"
    output:
        AtoDnumber = "synteny_analysis/blastp_results/AD_reciprocal_best/{Asample}_and_{Dsample}_recip.numbered.blastp"
    params:
        Asample = lambda wildcards: wildcards.Asample,
        Dsample = lambda wildcards: wildcards.Dsample
    threads: 1
    shell:
        """
        awk '{{printf("{params.Asample}_and_{params.Dsample}_gene_%d\\t%s\\n", NR, $0)}}' \
         {input.AtoDblastp} > {output.AtoDnumber}
        """

rule get_A_prots_from_recip_best:
    """
    This gets only the proteins from the reciprocal best hits for AD.
      - this limited set should not be used for blast.
    """
    input:
        AtoDblastp = "synteny_analysis/blastp_results/AD_reciprocal_best/{Asample}_and_{Dsample}_recip.numbered.blastp",
        Apep = "synteny_analysis/db/Asample/{Asample}_prots.pep",
        Dpep = "synteny_analysis/db/Dsample/{Dsample}_prots.pep"
    output:
        Alist = temp("synteny_analysis/db/AD_recipbest/Asample/{Asample}_and_{Dsample}_{Asample}_prots.list"),
        Dlist = temp("synteny_analysis/db/AD_recipbest/Dsample/{Asample}_and_{Dsample}_{Dsample}_prots.list"),
        Apep = "synteny_analysis/AD_files/{Asample}_and_{Dsample}/AD_{Asample}_and_{Dsample}.{Asample}.pep",
        Apdb = "synteny_analysis/AD_files/{Asample}_and_{Dsample}/AD_{Asample}_and_{Dsample}.{Asample}.pep.pdb",
        Dpep = "synteny_analysis/AD_files/{Asample}_and_{Dsample}/AD_{Asample}_and_{Dsample}.{Dsample}.pep",
        Dpdb = "synteny_analysis/AD_files/{Asample}_and_{Dsample}/AD_{Asample}_and_{Dsample}.{Dsample}.pep.pdb"
    threads: 1
    shell:
        """
        # A list
        cat {input.AtoDblastp} | \
          cut -f2 | sort | uniq > {output.Alist}
        # D list
        cat {input.AtoDblastp} | \
          cut -f3 | sort | uniq > {output.Dlist}
        # A prots
        seqtk subseq {input.Apep} {output.Alist} > {output.Apep}
        makeblastdb -in {output.Apep} -dbtype prot
        # D prots
        seqtk subseq {input.Dpep} {output.Dlist} > {output.Dpep}
        makeblastdb -in {output.Dpep} -dbtype prot
        """

rule make_pseudogenomes:
    """
    This takes the A-D reciprocal best hits and makes a pseudogenome, chromfile.
    """
    input:
        AtoDblastp = "synteny_analysis/blastp_results/AD_reciprocal_best/{Asample}_and_{Dsample}_recip.numbered.blastp",
        Achrom     = lambda wildcards: config["Aspecies"][wildcards.Asample]["prot_to_loc"],
        Dchrom     = lambda wildcards: config["Dspecies"][wildcards.Dsample]["prot_to_loc"]
    output:
        blastp     = "synteny_analysis/AD_files/{Asample}_and_{Dsample}/AD_{Asample}_and_{Dsample}.special.blastp",
        AtoDgenome = "synteny_analysis/AD_files/{Asample}_and_{Dsample}/AD_{Asample}_and_{Dsample}.fasta",
        AtoDchrom  = "synteny_analysis/AD_files/{Asample}_and_{Dsample}/AD_{Asample}_and_{Dsample}.chrom"
    threads: 1
    run:
        # copyfile
        # get dicts of gene_to_scaf to make a new dataframe with more info
        Achrom = pd.read_csv(input.Achrom,
                              header=None, sep = "\t")
        Achrom.columns = ["prot", "scaf", "direction", "start", "stop"]
        Dchrom = pd.read_csv(input.Dchrom,
                              header=None, sep = "\t")
        Dchrom.columns = ["prot", "scaf", "direction", "start", "stop"]

        #   about the gene locations
        blastdf = pd.read_csv(input.AtoDblastp,
                              header=None, sep = "\t")
        blastdf.columns = ["ADprot", "Agene", "Dgene",
                      "pident", "length", "mismatch",
                      "gapopen", "qstart", "qend",
                      "sstart", "send", "evalue", "bitscore"]
        blastdf.insert(2, "Ascaf",  [None for x in range(len(blastdf))])
        blastdf.insert(3, "Astart", [-1   for x in range(len(blastdf))])
        blastdf.insert(4, "Astop",  [-1   for x in range(len(blastdf))])
        blastdf.insert(6, "Dscaf",  [None for x in range(len(blastdf))])
        blastdf.insert(7, "Dstart", [-1   for x in range(len(blastdf))])
        blastdf.insert(8, "Dstop",  [-1   for x in range(len(blastdf))])
        # Finish setting up the paper
        blastdf["Ascaf"]  = blastdf["Agene"].map( dict(zip(Achrom.prot, Achrom.scaf)) )
        blastdf["Astart"] = blastdf["Agene"].map( dict(zip(Achrom.prot, Achrom.start)) )
        blastdf["Astop"]  = blastdf["Agene"].map( dict(zip(Achrom.prot, Achrom.stop)) )
        blastdf["Dscaf"]  = blastdf["Dgene"].map( dict(zip(Dchrom.prot, Dchrom.scaf)) )
        blastdf["Dstart"] = blastdf["Dgene"].map( dict(zip(Dchrom.prot, Dchrom.start)) )
        blastdf["Dstop"]  = blastdf["Dgene"].map( dict(zip(Dchrom.prot, Dchrom.stop)) )

        blastdf.insert(0, "ADchrom",  [-1 for x in range(len(blastdf))])
        for i, row in blastdf.iterrows():
            Ascaf = row["Ascaf"]
            Dscaf = row["Dscaf"]
            blastdf.loc[i, "ADchrom"] = "{}_and_{}".format(Ascaf, Dscaf)

        # ADchrom_to_size tracks the number of genes so we can sort by size
        ADchrom_to_size = {}
        for combo in blastdf["ADchrom"].unique():
            ADchrom_to_size[combo] = len(blastdf.loc[blastdf["ADchrom"] == combo,])
        sortedADcombo =[(k, v) for k, v in
                        sorted(ADchrom_to_size.items(), key=lambda item: item[1],
                               reverse = True)]
        # now go through the AD combos and generate a new assembly
        outchrom  = open(output.AtoDchrom,  "w")
        outgenome = open(output.AtoDgenome, "w")
        for chrom, num_genes in sortedADcombo:
            subdf = blastdf.loc[blastdf["ADchrom"] == chrom,]
            chromstart = 1
            for i, row in subdf.iterrows():
                chromstring = "{}\t{}\t+\t{}\t{}".format(
                    row["ADprot"], chrom, chromstart+399, chromstart + 599)
                print(chromstring, file = outchrom)
                chromstart += 10000
            chromseq = Seq("".join(["T"] * (chromstart-1)))
            chromrecord = SeqRecord(chromseq, id=chrom)
            SeqIO.write(chromrecord, outgenome, "fasta")
        outchrom.close()
        outgenome.close()
        blastdf.to_csv(output.blastp, sep="\t")

# now we need to figure out the reciprocal blast to just the BC and AD.
# We want to use the unfiltered A and D protein sets so that we don't lose
#  any information, or blast to something when a better possible hit has already
#  been filtered out.
#  Need to cat the reciprocal best together
rule blast_BC_against_A:
    input:
        BCpep =  "synteny_analysis/db/BCsample/{BCsample}_prots.pep",
        Apep  = "synteny_analysis/db/Asample/{Asample}_prots.pep",
        Apdb  = "synteny_analysis/db/Asample/{Asample}_prots.pep.pdb"
    output:
        Ablastp = "synteny_analysis/blastp_results/BCtoA/{BCsample}_against_{Asample}.blastp"
    threads: workflow.cores - 1
    shell:
        """
        # blast BC against A
        blastp -query {input.BCpep} -db {input.Apep} \
          -num_threads {threads} \
          -evalue 1E-5 \
          -outfmt 6 | \
          awk 'BEGIN{{former = ""}} \
               {{if ($1 != former){{print($0)}}; former=$1}}' > {output.Ablastp}
        """

rule blast_BC_against_D:
    input:
        BCpep =  "synteny_analysis/db/BCsample/{BCsample}_prots.pep",
        Dpep  = "synteny_analysis/db/Dsample/{Dsample}_prots.pep",
        Dpdb  = "synteny_analysis/db/Dsample/{Dsample}_prots.pep.pdb",
    output:
        Dblastp = "synteny_analysis/blastp_results/BCtoD/{BCsample}_against_{Dsample}.blastp"
    threads: workflow.cores - 1
    shell:
        """
        # blast BC against D
        blastp -query {input.BCpep} -db {input.Dpep} \
          -num_threads {threads} \
          -evalue 1E-5 \
          -outfmt 6 | \
          awk 'BEGIN{{former = ""}} \
               {{if ($1 != former){{print($0)}}; former=$1}}' > {output.Dblastp}
        """

rule blast_A_against_BC:
    input:
        Apep  = "synteny_analysis/db/Asample/{Asample}_prots.pep",
        BCpep = "synteny_analysis/db/BCsample/{BCsample}_prots.pep",
        BCpdp = "synteny_analysis/db/BCsample/{BCsample}_prots.pep.pdb"
    output:
        Ablastp = "synteny_analysis/blastp_results/AtoBC/{Asample}_against_{BCsample}.blastp"
    threads: workflow.cores - 1
    shell:
        """
        # blast A against BC
        blastp -query {input.Apep} -db {input.BCpep} \
          -num_threads {threads} \
          -evalue 1E-5 \
          -outfmt 6 | \
          awk 'BEGIN{{former = ""}} \
               {{if ($1 != former){{print($0)}}; former=$1}}' > {output.Ablastp}
        """

rule blast_D_against_BC:
    input:
        Dpep  = "synteny_analysis/db/Dsample/{Dsample}_prots.pep",
        BCpep = "synteny_analysis/db/BCsample/{BCsample}_prots.pep",
        BCpdp = "synteny_analysis/db/BCsample/{BCsample}_prots.pep.pdb"
    output:
        Dblastp = "synteny_analysis/blastp_results/DtoBC/{Dsample}_against_{BCsample}.blastp"
    threads: workflow.cores - 1
    shell:
        """
        # blast D against BC
        blastp -query {input.Dpep} -db {input.BCpep} \
          -num_threads {threads} \
          -evalue 1E-5 \
          -outfmt 6 | \
          awk 'BEGIN{{former = ""}} \
               {{if ($1 != former){{print($0)}}; former=$1}}' > {output.Dblastp}
        """

rule reciprocal_best_hits_A_and_BC:
    """
    finds the reciprocal best hits.
    reports it in the form of the blastp results from A->BC search
    """
    input:
        AtoBC_blastp = "synteny_analysis/blastp_results/AtoBC/{Asample}_against_{BCsample}.blastp",
        BCtoA_blastp = "synteny_analysis/blastp_results/BCtoA/{BCsample}_against_{Asample}.blastp"
    output:
        AtoBC_blastp = "synteny_analysis/blastp_results/AtoBC_reciprocal_best/{Asample}_against_{BCsample}.blastp"
    threads: 1
    run:
        OdpF.reciprocal_best_hits(input.AtoBC_blastp,
                                  input.BCtoA_blastp,
                                  output.AtoBC_blastp)

rule reciprocal_best_hits_D_and_BC:
    """
    finds the reciprocal best hits.
    reports it in the form of the blastp results from D->BC search
    """
    input:
        DtoBC_blastp = "synteny_analysis/blastp_results/DtoBC/{Dsample}_against_{BCsample}.blastp",
        BCtoD_blastp = "synteny_analysis/blastp_results/BCtoD/{BCsample}_against_{Dsample}.blastp"
    output:
        DtoBC_blastp = "synteny_analysis/blastp_results/DtoBC_reciprocal_best/{Dsample}_against_{BCsample}.blastp"
    threads: 1
    run:
        OdpF.reciprocal_best_hits(input.DtoBC_blastp,
                                  input.BCtoD_blastp,
                                  output.DtoBC_blastp)

rule annot_A_to_BC_recip:
    """
    For each protein in BC, we need to find if either A or D is better,
     then replace that protein name with the AD_gene name
    """
    input:
        AtoDblastp = "synteny_analysis/blastp_results/AD_reciprocal_best/{Asample}_and_{Dsample}_recip.numbered.blastp",
        AtoBC_blastp = "synteny_analysis/blastp_results/AtoBC_reciprocal_best/{Asample}_against_{BCsample}.blastp",
        DtoBC_blastp = "synteny_analysis/blastp_results/DtoBC_reciprocal_best/{Dsample}_against_{BCsample}.blastp"
    output:
        ADtoBC_blastp = "synteny_analysis/blastp_results/ADtoBC_reciprocal_best/{Asample}_and_{Dsample}_against_{BCsample}.blastp"
    params:
        Asample = lambda wildcards: wildcards.Asample,
        Dsample = lambda wildcards: wildcards.Dsample
    threads: 1
    run:
        # For this to work we need the final format to be just like a blastp
        #  results table. We need to iterate through the shared genes in the AD
        #  analysis, look in the AtoBC and DtoBC and pick whichever has the
        #  best hit.

        # Col1 is the new gene name
        # Col2 is the A gene name.
        # Col3 is the D gene name.
        AD_df = pd.read_csv(input.AtoDblastp, header=None, sep = "\t")
        AD_df.columns = ["ADgene", "Agene", "Dgene",
                      "pident", "length", "mismatch",
                      "gapopen", "qstart", "qend",
                      "sstart", "send", "evalue", "bitscore"]
        # now load the dfs for the A->BC and D->BC
        A_df = pd.read_csv(input.AtoBC_blastp, header=None, sep = "\t")
        A_df.columns = ["Agene", "BCgene",
                        "pident", "length", "mismatch",
                        "gapopen", "qstart", "qend",
                        "sstart", "send", "evalue", "bitscore"]
        A_df.insert(0, "ADgene",  [-1 for x in range(len(A_df))])
        A_df["ADgene"]  = AD_df["Agene"].map( dict(zip(AD_df.Agene, AD_df.ADgene)) )
        A_df = A_df.dropna()
        #A_df.to_csv(output.AtoBC_blastp, sep="\t")

        D_df = pd.read_csv(input.DtoBC_blastp, header=None, sep = "\t")
        D_df.columns = ["Dgene", "BCgene",
                        "pident", "length", "mismatch",
                        "gapopen", "qstart", "qend",
                        "sstart", "send", "evalue", "bitscore"]
        D_df.insert(0, "ADgene",  [-1 for x in range(len(D_df))])
        D_df["ADgene"]  = AD_df["Dgene"].map( dict(zip(AD_df.Dgene, AD_df.ADgene)) )
        D_df = D_df.dropna()
        #D_df.to_csv(output.DtoBC_blastp, sep="\t")

        # merged
        mergedf = A_df.append(D_df)
        mergedf = mergedf.reset_index(drop=True)

        # make a gene index for sorting later
        mergedf["AD_index"] = -1
        for i, row in mergedf.iterrows():
            index = row["ADgene"].split("_")[-1]
            mergedf.loc[i,"AD_index"] = int(index)

        # first, we pick the best hit for each gene in BC
        mergedf = mergedf.sort_values(by=["BCgene", "evalue", "pident"], ascending = [True, True,False])
        mergedf = mergedf.drop_duplicates(subset=["BCgene"])
        # Then we pick the best hit for each gene in AD
        mergedf = mergedf.sort_values(by=["AD_index", "evalue", "pident"], ascending = [True, True,False])
        mergedf = mergedf.drop_duplicates(subset=["ADgene"])
        mergedf = mergedf.reset_index(drop=True)

        # clean up the dataframe a little bit.
        #  Add two columns at the end with the species origin and the closest ortholog
        #  Delete the unnecessary columns. Now it is just blastp format.
        mergedf["AorD"] = np.NAN
        mergedf["ortholog"] = np.NAN
        for i, row in mergedf.iterrows():
            if pd.isnull(row["Agene"]):
                mergedf.loc[i,"AorD"] = params.Dsample
                mergedf.loc[i,"ortholog"] = row["Dgene"]
            elif pd.isnull(row["Dgene"]):
                mergedf.loc[i,"AorD"] = params.Asample
                mergedf.loc[i,"ortholog"] = row["Agene"]
        mergedf = mergedf.drop(["AD_index", "Agene", "Dgene"], axis=1)
        print(mergedf)
        print("These two values should be the same")
        print(len(mergedf["ADgene"].unique()))
        print(len(mergedf["BCgene"].unique()))
        print("The closest orthologs are here")
        print(mergedf["AorD"].value_counts())
        mergedf.to_csv(output.ADtoBC_blastp, sep="\t", index = False, header = False)

rule get_genome_coords_AD:
    input:
        genome = "synteny_analysis/AD_files/{Asample}_and_{Dsample}/AD_{Asample}_and_{Dsample}.fasta"
    output:
        coords = "synteny_analysis/genome_coords/AD_genome_coords/{Asample}_and_{Dsample}_genomecoords.txt"
    threads:
        1
    params:
        minsize = 300000
    shell:
        """
        bioawk -cfastx '{{ if (length($seq) >= {params.minsize}) {{ \
                           print($name, length($seq), sum)  }} \
                        }}' {input.genome} | \
          sort -k2 -nr | \
          awk '{{sum = sum + $2; print($1, $2, sum, sum - $2) }}' > {output.coords}
        """

rule get_genome_coords_BC:
    input:
        genome = lambda wildcards: config["BCspecies"][wildcards.BCsample]["genome"]
    output:
        coords = "synteny_analysis/genome_coords/BC_genome_coords/{BCsample}_genomecoords.txt",
    threads:
        1
    params:
        minsize = lambda wildcards: config["BCspecies"][wildcards.BCsample]["minscafsize"]
    shell:
        """
        bioawk -cfastx '{{ if (length($seq) >= {params.minsize}) {{ \
                           print($name, length($seq), sum)  }} \
                        }}' {input.genome} | \
          sort -k2 -nr | \
          awk '{{sum = sum + $2; print($1, $2, sum, sum - $2) }}' > {output.coords}
        """

rule generate_plotting_df_and_plot_order:
    """
    This parses all of the various types of input and generates the df that
     contains the plotting information like genes, reciprocal-best orthologs.

    Also outputs a file of the plotting order.
    """
    input:
        BCcoords = "synteny_analysis/genome_coords/BC_genome_coords/{BCsample}_genomecoords.txt",
        ADcoords = "synteny_analysis/genome_coords/AD_genome_coords/{Asample}_and_{Dsample}_genomecoords.txt",
        BCprottoloc = lambda wildcards: config["BCspecies"][wildcards.BCsample]["prot_to_loc"],
        ADprottoloc = "synteny_analysis/AD_files/{Asample}_and_{Dsample}/AD_{Asample}_and_{Dsample}.chrom",
        recip = "synteny_analysis/blastp_results/ADtoBC_reciprocal_best/{Asample}_and_{Dsample}_against_{BCsample}.blastp"
    output:
        table = "synteny_analysis/dvalue_table/{Asample}_and_{Dsample}_against_{BCsample}_info.tsv",
        plot_order = "synteny_analysis/plot_order/{Asample}_and_{Dsample}_against_{BCsample}_plotorder.tsv"
    threads:
        1
    params:
        Asample   = lambda wildcards: wildcards.Asample,
        Dsample   = lambda wildcards: wildcards.Dsample,
        BCsample  = lambda wildcards: wildcards.BCsample,
    run:
        # We need to make these files special because it is difficult to
        #  accommodate multiple files for A, D, and BC

        # The coord files look like this:
        #    sca3_and_SWAQ01000010.1 670000 670000 0
        #    sca1_and_SWAQ01001661.1 630000 1300000 670000
        #    sca4_and_SWAQ01000558.1 570000 1870000 1300000
        #    sca2_and_SWAQ01001676.1 520000 2390000 1870000
        #    sca1_and_SWAQ01001657.1 430000 2820000 2390000

        # load the AD genomecoords file
        AD_coords = pd.read_csv(input.ADcoords, header=None, sep = " ")
        AD_coords.columns = ["scaf", "length", "end", "start"]
        # load the BC genomecoords file
        BC_coords = pd.read_csv(input.BCcoords, header=None, sep = " ")
        BC_coords.columns = ["scaf", "length", "end", "start"]
        print(AD_coords)
        print(BC_coords)

        # load the AD chrom
        AD_chrom = pd.read_csv(input.ADprottoloc, header=None, sep = "\t")
        AD_chrom.columns = ["prot", "scaf", "direction", "start", "stop"]
        # load the BC chrom
        BC_chrom = pd.read_csv(input.BCprottoloc, header=None, sep = "\t")
        BC_chrom.columns = ["prot", "scaf", "direction", "start", "stop"]


        # load the blast results
        # the results look like this:
        #    caps_and_rhopilema_gene_1       Hcv1.av93.c2.g1569.i1   55.0    500     225     0       148     647     139     638     0.0     582.0   rhopilema       mRNA.RE00017
        #    caps_and_rhopilema_gene_2       Hcv1.av93.c11.g316.i1   37.766  188     111     2       4       188     339     523     1.7899999999999997e-31  119.0   rhopilema       mRNA.RE00018
        #    caps_and_rhopilema_gene_3       Hcv1.av93.c11.g830.i1   65.497  513     160     5       205     716     234     730     0.0     697.0   caps    XP_004341842.1
        #    caps_and_rhopilema_gene_4       Hcv1.av93.c6.g1083.i1   31.22   205     124     8       34      232     18      211     6.29e-24        94.7    rhopilema       mRNA.RE00048
        blastdf = pd.read_csv(input.recip, header=None, sep = "\t")
        blastdf.columns = ["ADgene", "BCgene",
                        "pident", "length", "mismatch",
                        "gapopen", "qstart", "qend",
                        "sstart", "send", "evalue",
                        "bitscore", "species", "ortholog"]
        # the df needs to eventually have these columns
        #  xgene   ygene   bitscore
        #  evalue  xstart  xmiddle xstop
        #  ystart  ymiddle ystop   yscaf
        #  xscaf   Dx      Dx_barleft
        #  Dx_barmiddle    Dx_barright     Dx_barwidth
        #  Dy      Dy_barleft      Dy_barmiddle    Dy_barright     Dy_barwidth
        blastdf["xgene"] = blastdf["ADgene"]
        blastdf["ygene"] = blastdf["BCgene"]
        blastdf["xspecies"] = blastdf["species"]
        blastdf["xortholog"] = blastdf["ortholog"]
        blastdf = blastdf[["xgene", "ygene", "bitscore", "evalue", "xspecies", "xortholog"]]

        for newcolumn in ["xstart",       "xmiddle",      "xstop",
                          "ystart",       "ymiddle",      "ystop",
                          "yscaf",        "xscaf",        "Dx",
                          "Dx_barleft",   "Dx_barmiddle", "Dx_barright",
                          "Dx_barwidth",  "Dy",           "Dy_barleft",
                          "Dy_barmiddle", "Dy_barright",  "Dy_barwidth"]:
            blastdf[newcolumn] = -1

        #blastdf = blastdf[["xgene", "ygene", "bitscore", "evalue", "xspecies", "xortholog"]]

        blastdf["Dx"]   = 5
        blastdf["Dy"]   = 5
        blastdf["yscaf"] = blastdf["ygene"].map(dict(zip(BC_chrom.prot, BC_chrom.scaf)) )
        blastdf["xscaf"] = blastdf["xgene"].map(dict(zip(AD_chrom.prot, AD_chrom.scaf)) )
        # xaxis
        blastdf["xoffset"] =      blastdf["xscaf"].map(dict(zip(AD_coords.scaf, AD_coords.start)) )
        blastdf["xstart_temp"]  = blastdf["xgene"].map(dict(zip(AD_chrom.prot, AD_chrom.start)) )
        blastdf["xstop_temp"]   = blastdf["xgene"].map(dict(zip(AD_chrom.prot, AD_chrom.stop)) )
        blastdf["xmiddle_temp"] = blastdf["xstart_temp"] + (blastdf["xstop_temp"] - blastdf["xstart_temp"])/2
        blastdf["xstart"]  = blastdf["xstart_temp"]  + blastdf["xoffset"]
        blastdf["xstop"]   = blastdf["xstop_temp"]   + blastdf["xoffset"]
        blastdf["xmiddle"] = blastdf["xmiddle_temp"] + blastdf["xoffset"]
        # yaxis
        blastdf["yoffset"] =      blastdf["yscaf"].map(dict(zip(BC_coords.scaf, BC_coords.start)) )
        blastdf["ystart_temp"]  = blastdf["ygene"].map(dict(zip(BC_chrom.prot,  BC_chrom.start)) )
        blastdf["ystop_temp"]   = blastdf["ygene"].map(dict(zip(BC_chrom.prot,  BC_chrom.stop)) )
        blastdf["ymiddle_temp"] = blastdf["ystart_temp"] + (blastdf["ystop_temp"] - blastdf["ystart_temp"])/2
        blastdf["ystart"]  = blastdf["ystart_temp"]  + blastdf["yoffset"]
        blastdf["ystop"]   = blastdf["ystop_temp"]   + blastdf["yoffset"]
        blastdf["ymiddle"] = blastdf["ymiddle_temp"] + blastdf["yoffset"]
        # dxvalues
        blastdf["Dx_barleft"]   = blastdf["xstart"]
        blastdf["Dx_barmiddle"] = blastdf["xmiddle"]
        blastdf["Dx_barright"]  = blastdf["xstop"]
        blastdf["Dx_barwidth"]  = blastdf["xstop"] - blastdf["xstart"]
        #dy values
        blastdf["Dy_barleft"]   = blastdf["ystart"]
        blastdf["Dy_barmiddle"] = blastdf["ymiddle"]
        blastdf["Dy_barright"]  = blastdf["ystop"]
        blastdf["Dy_barwidth"]  = blastdf["ystop"] - blastdf["ystart"]

        blastdf = blastdf.drop(columns=["xoffset", "xstart_temp", "xstop_temp", "xmiddle_temp"])
        blastdf = blastdf.drop(columns=["yoffset", "ystart_temp", "ystop_temp", "ymiddle_temp"])

        # drop the empty rows
        blastdf = blastdf.dropna()
        blastdf = blastdf.reset_index(drop=True)
        blastdf.to_csv(output.table, sep="\t", index = True, header = True)

        # now we print out the plot order file
        # looks like this:
        #   xplotorder:
        #     - scaffold_0001
        #     - scaffold_0002
        #     - scaffold_0003
        #   yplotorder:
        #     - c1
        #     - c2
        #     - c3
        with open(output.plot_order, "w") as f:
            print("xplotorder:", file = f)
            for i, row in AD_coords.iterrows():
                print("  - {}".format(row["scaf"]), file = f)
            print("yplotorder:", file = f)
            for i, row in BC_coords.iterrows():
                print("  - {}".format(row["scaf"]), file = f)

rule generate_breaks_file:
    """
    This rule handles generating a file that defines the breaks within individual
     scaffolds. This process will:
      - automatically define breaks if the user wants
      - manually add breaks that are defined in the config file
      - manually remove breaks defined in the config file.

    Input for the rule:
      - the plotting df
      - the genomecoords for both axes

    Output for the rule:
      - a subsection of the plotting df that defines where the breaks are
    """
    input:
        table = "synteny_analysis/dvalue_table/{Asample}_and_{Dsample}_against_{BCsample}_info.tsv",
        ycoords = "synteny_analysis/genome_coords/BC_genome_coords/{BCsample}_genomecoords.txt",
        xcoords = "synteny_analysis/genome_coords/AD_genome_coords/{Asample}_and_{Dsample}_genomecoords.txt",
    output:
        xtable = "synteny_analysis/dvalue_table_breaks/{Asample}_and_{Dsample}_against_{BCsample}_xbreaks_{man_or_auto}.tsv",
        ytable = "synteny_analysis/dvalue_table_breaks/{Asample}_and_{Dsample}_against_{BCsample}_ybreaks_{man_or_auto}.tsv"
    threads:
        1
    params:
        man_or_auto = lambda wildcards: wildcards.man_or_auto,
        ybreaks  = lambda wildcards: config["BCspecies"][wildcards.BCsample]["manual_breaks"],
    run:
        # the breaks are a dict have scafs as key, list of breaks as the values
        x_breaks = {}
        y_breaks = {}
        for string in params.ybreaks:
            splitd   = string.split(":")
            scaf     = splitd[0]
            position = int(splitd[1])
            if scaf not in y_breaks:
                y_breaks[scaf] = set()
            y_breaks[scaf].add(position)
        x_offset = OdpF.genome_coords_to_plotstart_dict(input.xcoords)
        y_offset = OdpF.genome_coords_to_plotstart_dict(input.ycoords)

        print("printing the input before finding the breaks")
        df = pd.read_csv(input.table, delimiter="\t", index_col=0)
        df["xgene"] = df["xgene"].astype(str)
        df["ygene"] = df["ygene"].astype(str)
        print(df)

        if params.man_or_auto == "manual":
            # parse the manual breaks in the config file
            print("  - Getting the manual breaks for x")
            xdf = OdpF.determine_breaks(df, x_breaks, x_offset, "x", False)
            print("  - Getting the manual breaks for y")
            ydf = OdpF.determine_breaks(df, y_breaks, y_offset, "y", False)
            # save the results to a file
            xdf.to_csv(output.xtable, sep="\t")
            ydf.to_csv(output.ytable, sep="\t")
        elif params.man_or_auto == "auto":
            # auto-determine the breaks if we need them
            print("  - Determining the new xbreaks automatically.")
            xdf = determine_breaks(df, x_breaks, x_offset, "x", True)
            print("  - Determining the new ybreaks automatically.")
            ydf = determine_breaks(df, y_breaks, y_offset, "y", True)
            # save the results to a file
            xdf.to_csv(output.xtable, sep="\t")
            ydf.to_csv(output.ytable, sep="\t")

rule plot_synteny:
    """
    This makes the synteny plot without doing any special coloring of the dots
    """
    input:
        dtable = "synteny_analysis/dvalue_table/{Asample}_and_{Dsample}_against_{BCsample}_info.tsv",
        plot_order = "synteny_analysis/plot_order/{Asample}_and_{Dsample}_against_{BCsample}_plotorder.tsv",
        ycoords = "synteny_analysis/genome_coords/BC_genome_coords/{BCsample}_genomecoords.txt",
        xcoords = "synteny_analysis/genome_coords/AD_genome_coords/{Asample}_and_{Dsample}_genomecoords.txt",
        xbreaks_manual = "synteny_analysis/dvalue_table_breaks/{Asample}_and_{Dsample}_against_{BCsample}_xbreaks_manual.tsv",
        ybreaks_manual = "synteny_analysis/dvalue_table_breaks/{Asample}_and_{Dsample}_against_{BCsample}_ybreaks_manual.tsv",
        xprottoloc = "synteny_analysis/AD_files/{Asample}_and_{Dsample}/AD_{Asample}_and_{Dsample}.chrom",
        yprottoloc = lambda wildcards: config["BCspecies"][wildcards.BCsample]["prot_to_loc"],
        recip = "synteny_analysis/blastp_results/ADtoBC_reciprocal_best/{Asample}_and_{Dsample}_against_{BCsample}.blastp"
    output:
        synplot_manual = "synteny_analysis/plots/synteny_uncolored/{Asample}_and_{Dsample}_against_{BCsample}_synteny_manualbreaks.pdf"
    threads:
        1
    params:
        xsample  = lambda wildcards: "{}_and_{}".format(wildcards.Asample, wildcards.Dsample),
        ysample  = lambda wildcards: wildcards.BCsample,
        keep_x   = True,
        keep_y   = True,
    run:
        synteny_plot(input.dtable, input.plot_order, input.xcoords,  input.ycoords,
                     params.xsample, params.ysample,
                     input.xbreaks_manual, input.ybreaks_manual,
                     output.synplot_manual, None,           False,
                     plot_x_lines = params.keep_x,
                     plot_y_lines = params.keep_y, config = config)

def synteny_plot(plotting_df,    plot_order, xcoords_file,
                 ycoords_file,   xsample,    ysample,
                 xbreaks_file,   ybreaks_file,
                 synplot,        prot_to_color,  dropmissing,
                 plot_x_lines = False,
                 plot_y_lines = False,
                 xprottoloc = False,
                 yprottoloc = False, **kwargs):
    """
    If the user provided a plot order, then we should not skip any scaffolds.

    This is the main plotting script for the synteny plot
    """
    xorder = []
    yorder = []
    inx = False
    iny = False
    # load up the plotting order
    with open(plot_order, "r") as f:
        for line in f:
            line = line.strip()
            if line:
                if line == "xplotorder:":
                    inx = True
                    iny = False
                elif line == "yplotorder:":
                    inx = False
                    iny = True
                else:
                    entry = line.split(" ")[-1]
                    if inx:
                        xorder.append(entry)
                    elif iny:
                        yorder.append(entry)
    col_name = "scaf"
    # first we load up the x-axis coords and the ycoords
    xcoords_df = pd.read_csv(xcoords_file, delimiter=" ", header = None)
    xcoords_df.columns = ["scaf", "length", "stop", "start"]
    xcoords_df = xcoords_df.drop(["stop", "start"], axis = 1)
    xcoords_df = xcoords_df[xcoords_df["scaf"].isin(xorder)]
    # Create a dummy df with the required list and the col name to sort on
    dummy = pd.Series(xorder, name = col_name).to_frame()
    # Use left merge on the dummy to return a sorted df
    xcoords_df = dummy.merge(xcoords_df, on = col_name, how = "left")
    xcoords_df = xcoords_df.dropna()
    xcoords_df["start"]  = xcoords_df["length"].cumsum() - xcoords_df["length"]
    xcoords_df["stop"]   = xcoords_df["length"].cumsum()
    xcoords_df["middle"] = xcoords_df["start"] + (xcoords_df["stop"] - xcoords_df["start"])/2

    ycoords_df = pd.read_csv(ycoords_file, delimiter=" ", header = None)
    ycoords_df.columns = ["scaf", "length", "stop", "start"]
    ycoords_df = ycoords_df.drop(["stop", "start"], axis = 1)
    ycoords_df = ycoords_df[ycoords_df["scaf"].isin(yorder)]
    # Create a dummy df with the required list and the col name to sort on
    dummy = pd.Series(yorder, name = col_name).to_frame()
    # Use left merge on the dummy to return a sorted df
    ycoords_df = dummy.merge(ycoords_df, on = col_name, how = "left")
    ycoords_df = ycoords_df.dropna()
    ycoords_df["start"] = ycoords_df["length"].cumsum() - ycoords_df["length"]
    ycoords_df["stop"]  = ycoords_df["length"].cumsum()
    ycoords_df["middle"] = ycoords_df["start"] + (ycoords_df["stop"] - ycoords_df["start"])/2

    config = kwargs["config"]
    import seaborn as sns; sns.set()
    import matplotlib
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    #import matplotlib.patches as mplpatches
    from matplotlib.ticker import StrMethodFormatter, NullFormatter
    # set seaborn stuff
    #sns.set(rc={'text.usetex' : True})
    sns.set_style("ticks", {'font.family': ['sans-serif'],
                                'font.sans-serif': ['Helvetica'],
                                'grid.color': '.95'})
    # Preserve the vertical order of embedded images:
    matplotlib.rcParams['image.composite_image'] = False
    # text as font in pdf
    matplotlib.rcParams['pdf.fonttype'] = 42
    matplotlib.rcParams['ps.fonttype'] = 42

    # open the xbreaks and the ybreaks dataframes
    # These are where there are low-opacity,
    #  dotted lines to show breaks in synteny
    # example entries are like this:
    xbreaks_df = pd.read_csv(xbreaks_file, delimiter="\t", index_col=0)
    xbreaks_df["xgene"] = xbreaks_df["xgene"].astype(str)
    xbreaks_df["ygene"] = xbreaks_df["ygene"].astype(str)
    ybreaks_df = pd.read_csv(ybreaks_file, delimiter="\t", index_col=0)
    ybreaks_df["xgene"] = ybreaks_df["xgene"].astype(str)
    ybreaks_df["ygene"] = ybreaks_df["ygene"].astype(str)

    # first make a lookup table
    df = pd.read_csv(plotting_df, delimiter="\t", index_col=0)
    df["xgene"] = df["xgene"].astype(str)
    df["ygene"] = df["ygene"].astype(str)

    xgene = df["xgene"]
    x = df["xmiddle"]
    y = df["ymiddle"]
    bitscore = df["bitscore"]

    print("found {} points to plot".format(len(df["xmiddle"])))
    print("max bitscore: ", max(bitscore))
    bitscore_adjusted = [(x/max(bitscore))*60 for x in bitscore]
    colors = [(0, 0, 1.0, min( 1.0, (x/max(bitscore))*(max(bitscore)/np.mean(bitscore)))) for x in bitscore]
    drops = set()
    if prot_to_color:
        for i in range(len(xgene)):
            alpha = colors[i][3]
            try:
                newcolor = list(matplotlib.colors.to_rgba(prot_to_color[xgene[i]]))
            except:
                print("couldn't find a color for: {}".format(xgene[i]))
                newcolor = [0,0,0,1]
                drops.add(i)
            newcolor[3] = alpha
            colors[i] = newcolor

    # now make a scatter plot
    figWidth = 8
    figHeight = 8
    plt.figure(figsize=(figWidth,figHeight))
    #set the panel dimensions
    panelWidth = 4
    panelHeight = 4
    dpanel_width = 0.25
    #find the margins to center the panel in figure
    leftMargin = (figWidth - panelWidth)/2
    bottomMargin = ((figHeight - panelHeight)/2)
    panel1 = plt.axes([leftMargin/figWidth, #left
                         bottomMargin/figHeight,    #bottom
                         panelWidth/figWidth,   #width
                         panelHeight/figHeight])     #height
    panelxd = plt.axes([leftMargin/figWidth, #left
                         (bottomMargin+panelHeight+0.1)/figHeight,    #bottom
                         panelWidth/figWidth,   #width
                         dpanel_width/figHeight])     #height
    panelyd = plt.axes([(leftMargin+panelWidth + 0.1)/figWidth, #left
                         bottomMargin/figHeight,    #bottom
                         dpanel_width/figWidth,   #width
                         panelHeight/figHeight])     #height
    panel1.tick_params(axis='both',which='both',
                        bottom=False, labelbottom=True,
                        left=False, labelleft=True,
                        right=False, labelright=False,
                        top=False, labeltop=False)
    panelxd.tick_params(axis='both',which='both',
                        bottom=False, labelbottom=False,
                        left=False, labelleft=False,
                        right=False, labelright=False,
                        top=False, labeltop=False)
    panelyd.tick_params(axis='both',which='both',
                        bottom=False, labelbottom=False,
                        left=False, labelleft=False,
                        right=False, labelright=False,
                        top=False, labeltop=False)
    # set the panel linewidth thinner
    for this_panel in [panel1, panelxd, panelyd]:
        for axis in ['top','bottom','left','right']:
            this_panel.spines[axis].set_linewidth(0.5)
    # turn off the axis spines
    for this_panel in [panelxd, panelyd]:
        this_panel.spines['top'].set_visible(False)
        this_panel.spines['right'].set_visible(False)

    panel1.scatter(x, y, color = colors,
                   ec = None, s=6, linewidths = 0)
    xmax = xcoords_df["stop"].iloc[-1]
    ymax = ycoords_df["stop"].iloc[-1]
    # set mins and max
    panel1.set_xlim([0, xmax])
    panel1.set_ylim([0, ymax])

    # xtick positions and ytick positions
    xtickpos   = xcoords_df["middle"]
    xticklabel = xcoords_df["scaf"]
    xoffset    = xcoords_df["start"]
    xend       = xcoords_df["stop"]
    ## set x ticks
    newarr = []
    newarrlabels=[]
    if not plot_x_lines:
        # there are inevitably going to be many scaffolds. We need to subset
        #  get a list of evenly spaced indices
        numElems = min(20, len(xtickpos)) # this could break if there are fewer elements
        arr = xtickpos
        idx = np.round(np.linspace(0, len(arr) - 1, numElems)).astype(int)
        newarr       = [arr[i] for i in idx]
        newarrNumScaf     = [i for i in idx]
        # turn on y-axis ticks on the left - plot scaffolds
        panel1.tick_params(bottom=True)
        panel1.set_xticks(newarr)
        panel1.set_xticklabels(newarrNumScaf, fontsize=4, rotation=90)
        panel1.set_xlabel(xsample + " number of scaffolds")
    else:
        newarr = [0] + list(xend)
        panel1.set_xticks(xtickpos)
        panel1.set_xticklabels(xticklabel, fontsize=4, rotation = 90)
        panel1.set_xlabel(xsample + " scaffolds")
    # turn on x-axis ticks on the Dx plot
    newarrlabels = [round(x/1000000, 1) for x in newarr]
    panelxd.tick_params(top=True, labeltop=True)
    panelxd.set_xticks(newarr)
    panelxd.set_xticklabels(newarrlabels, fontsize=4, rotation=90)
    panelxd.xaxis.set_label_position("top")
    panelxd.set_xlabel("Mb")

    # set y ticks
    ytickpos   = ycoords_df["middle"]
    yticklabel = ycoords_df["scaf"]
    yoffset    = ycoords_df["start"]
    yend       = ycoords_df["stop"]
    newarr=[]
    newarrlabels=[]
    if not plot_y_lines:
        #there are inevitably going to be many scaffolds. We need to subset
        # get a list of evenly spaced indices
        numElems = min(20, len(ytickpos))
        arr = ytickpos
        idx = np.round(np.linspace(0, len(arr) - 1, numElems)).astype(int)
        newarr       = [arr[i] for i in idx]
        newarrlabels = [round(arr[i]/1000000, 1) for i in idx]
        newarrNumScaf     = [i for i in idx]
        # turn on y-axis ticks on the left - plot scaffolds
        panel1.tick_params(left=True)
        panel1.set_yticks(newarr)
        panel1.set_yticklabels(newarrNumScaf, fontsize=8)
        panel1.set_ylabel(ysample + " number of scaffolds")
    else:
        newarr = [0] + list(yend)
        panel1.set_yticks(ytickpos)
        panel1.set_yticklabels(yticklabel, fontsize=8)
        panel1.set_ylabel(ysample + " scaffolds")
    # turn on y-axis ticks on the Dy plot
    newarrlabels = [round(x/1000000, 1) for x in newarr]
    panelyd.tick_params(right=True, labelright=True)
    panelyd.set_yticks(newarr)
    panelyd.set_yticklabels(newarrlabels, fontsize=8)
    panelyd.yaxis.set_label_position("right")
    panelyd.set_ylabel("Mb")

    # set the x and y labels on Dy and Dx
    panelxd.bar(x = df["Dx_barmiddle"], height=df["Dx"], width = df["Dx_barwidth"],
                align = "center", lw=0, color="blue", zorder = 2)
    panelxd.set_xlim([0,xmax])
    panelxd.set_ylabel('Dx', fontsize=10)

    panelyd.barh(y = df["Dy_barmiddle"], width=df["Dy"], height = df["Dy_barwidth"],
                 align = "center", lw=0, color="blue", zorder = 2)
    panelyd.set_ylim([0,ymax])
    panelyd.set_xlabel('Dy', fontsize=10)

    for this_axis in [panel1, panelxd, panelyd]:
        this_axis.xaxis.get_offset_text().set_visible(False)
        this_axis.yaxis.get_offset_text().set_visible(False)

    #plot vertical lines
    for value in xoffset[1:]:
        panel1.axvline(x=value, color="black", lw=0.5)
    #plot horizontal lines
    for value in yoffset[1:]:
        panel1.axhline(y=value, color="black", lw=0.5)

    # plot vertical BOS
    for value in xbreaks_df["xmiddle"]:
        panel1.axvline(x=value, color=[0,0,0,0.25], lw=0.5, linestyle="dotted")
    # plot horizontal BOS
    for value in ybreaks_df["ymiddle"]:
        panel1.axhline(y=value, color=[0,0,0,0.25], lw=0.5, linestyle="dotted")
    plt.savefig(synplot)

def sizes_and_scale_minp(smallest_p):
    """
    This outputs two lists. One of scale, and one of sizes,
    based on the smallest_p.

    This is used for plotting elipses in the figure and the legend
    """
    scale     = [1,       0.84,     0.67,     0.5,    0.3   ]

    if smallest_p == 0:
        sizes = [0,       "1E-20", "1E-10", "1E-5", "1E-2"]
    elif smallest_p <= float("1E-20"):
        sizes = ["1E-20", "1E-15", "1E-7",  "1E-4", "5E-2"]
    elif smallest_p <= float("1E-15"):
        sizes = ["1E-15", "1E-10", "1E-5",  "1E-2", "1E-1"]
    elif smallest_p <= float("1E-10"):
        sizes = ["1E-10", "1E-7",  "1E-4",  "1E-2", "1E-1"]
    elif smallest_p <= float("1E-8"):
        sizes = ["1E-8",  "1E-6",  "1E-4",  "1E-2", "1E-1"]
    elif smallest_p <= float("1E-6"):
        sizes = ["1E-6",  "1E-5",  "1E-3",  "1E-2", "1E-1"]
    elif smallest_p <= float("1E-5"):
        sizes = ["1E-5",  "1E-4",  "1E-3",  "1E-2", "0.5"]
    else:
        sizes = ["1E-4",  "1E-3",  "1E-2",  "1E-1", "0.5"]
    return [scale, sizes]

def quantize_pvalue(xsize, ysize, p, smallest_p):
    """
    This quantizes the pvalues using standard values cutoffs
    returns [xsize, ysize]
    """
    scale, sizes = sizes_and_scale_minp(smallest_p)
    for i in range(len(sizes)):
        if p <= float(sizes[i]):
            return [xsize * scale[i], ysize * scale[i]]
    return [xsize * 0.15, ysize * 0.15]

def fishers_exact(plotting_df, plot_order,
                  xcoords_file, ycoords_file,
                  xsample,      ysample,
                  xbreaks_file, ybreaks_file,
                  outdf, style):
    """
    This test performs fishers exact test on the genome based on reciprocal
     best hits, and breaks.

    There are two styles, "whole" & "breaks"
      - "whole" is conducted by performing Fisher's exact on whole scaffolds
      - "breaks" is conducted by performing the test on pieces of scaffolds
    """
    xorder = []
    yorder = []
    inx = False
    iny = False
    # load up the plotting order
    with open(plot_order, "r") as f:
        for line in f:
            line = line.strip()
            if line:
                if line == "xplotorder:":
                    inx = True
                    iny = False
                elif line == "yplotorder:":
                    inx = False
                    iny = True
                else:
                    entry = line.split(" ")[-1]
                    if inx:
                        xorder.append(entry)
                    elif iny:
                        yorder.append(entry)

    col_name = "scaf"
    # first we load up the x-axis coords and the ycoords
    xcoords_df = pd.read_csv(xcoords_file, delimiter=" ", header = None)
    xcoords_df.columns = ["scaf", "length", "stop", "start"]
    xcoords_df = xcoords_df.drop(["stop", "start"], axis = 1)
    xcoords_df = xcoords_df[xcoords_df["scaf"].isin(xorder)]
    # Create a dummy df with the required list and the col name to sort on
    dummy = pd.Series(xorder, name = col_name).to_frame()
    # Use left merge on the dummy to return a sorted df
    xcoords_df = dummy.merge(xcoords_df, on = col_name, how = "left")
    xcoords_df = xcoords_df.dropna()
    xcoords_df["start"]  = xcoords_df["length"].cumsum() - xcoords_df["length"]
    xcoords_df["stop"]   = xcoords_df["length"].cumsum()
    xcoords_df["middle"] = xcoords_df["start"] + (xcoords_df["stop"] - xcoords_df["start"])/2

    ycoords_df = pd.read_csv(ycoords_file, delimiter=" ", header = None)
    ycoords_df.columns = ["scaf", "length", "stop", "start"]
    ycoords_df = ycoords_df.drop(["stop", "start"], axis = 1)
    ycoords_df = ycoords_df[ycoords_df["scaf"].isin(yorder)]
    # Create a dummy df with the required list and the col name to sort on
    dummy = pd.Series(yorder, name = col_name).to_frame()
    # Use left merge on the dummy to return a sorted df
    ycoords_df = dummy.merge(ycoords_df, on = col_name, how = "left")
    ycoords_df = ycoords_df.dropna()
    ycoords_df["start"] = ycoords_df["length"].cumsum() - ycoords_df["length"]
    ycoords_df["stop"]  = ycoords_df["length"].cumsum()
    ycoords_df["middle"] = ycoords_df["start"] + (ycoords_df["stop"] - ycoords_df["start"])/2

    x_offset      = dict(zip(xcoords_df.scaf, xcoords_df.start))
    x_scaf_to_len = dict(zip(xcoords_df.scaf, xcoords_df.length))
    y_offset      = dict(zip(ycoords_df.scaf, ycoords_df.start))
    y_scaf_to_len = dict(zip(ycoords_df.scaf, ycoords_df.length))

    from scipy import stats
    # open the xbreaks and the ybreaks dataframes
    # These are where there are low-opacity,
    #  dotted lines to show breaks in synteny
    # example entries are like this:
    xbreaks_df = pd.read_csv(xbreaks_file, delimiter="\t", index_col=0)
    ybreaks_df = pd.read_csv(ybreaks_file, delimiter="\t", index_col=0)

    # first make a lookup table
    df = pd.read_csv(plotting_df, delimiter="\t", index_col=0)
    df["xgene"] = df["xgene"].astype(str)
    df["ygene"] = df["ygene"].astype(str)

    fisher_dict = []
    if style == "breaks":
        xranges_to_dfdict = {}
        yranges_to_dfdict = {}
        print("generating breaks dfs for x scaffolds")
        for xscaf in xorder:
            plot_xmin  = x_offset[xscaf]
            plot_xmax  = x_offset[xscaf] + x_scaf_to_len[xscaf]
            subxdf = xbreaks_df.loc[xbreaks_df["xscaf"] == xscaf, ]
            subxdf = subxdf.sort_values(by=["xstop"])
            xbreaks = [plot_xmin] + list(subxdf["xstop"]) + [plot_xmax]
            for xi in range(len(xbreaks)-1):
                plotleft   = xbreaks[xi]
                plotright  = xbreaks[xi+1]
                query = "xmiddle >= {} & xmiddle < {}".format(plotleft, plotright)
                inxdf  = df.query(query)
                outxdf = df[~df.isin(inxdf).all(1)]
                interval = "{}:{}-{}".format(xscaf, plotleft, plotright)
                xranges_to_dfdict[interval] = {"in": inxdf, "out": outxdf}
        print("generating breaks dfs for y scaffolds")
        for yscaf in yorder:
            plot_ymin  = y_offset[yscaf]
            plot_ymax  = y_offset[yscaf] + y_scaf_to_len[yscaf]
            subydf = ybreaks_df.loc[ybreaks_df["yscaf"] == yscaf, ]
            subydf = subydf.sort_values(by=["ystop"])
            ybreaks = [plot_ymin] + list(subydf["ystop"]) + [plot_ymax]
            for yi in range(len(ybreaks)-1):
                plotbottom = ybreaks[yi]
                plottop    = ybreaks[yi+1]
                query = "ymiddle >= {} & ymiddle < {}".format(plotbottom, plottop)
                inydf  = df.query(query)
                outydf = df[~df.isin(inydf).all(1)]
                interval = "{}:{}-{}".format(yscaf, plotbottom, plottop)
                yranges_to_dfdict[interval] = {"in": inydf, "out": outydf}
        # now that we have each interval and their respective dfs, we
        #  iterate through everything and make the fisher's exact test entry
        counter = 0
        num_variations = len(xranges_to_dfdict) * len(yranges_to_dfdict)
        for xinterval in xranges_to_dfdict:
            for yinterval in yranges_to_dfdict:
                counter += 1
                print("\r    Completed {}/{} interval calculations   ".format(counter, num_variations), end = "")
                xscaf     = xinterval.split(":")[0]
                plotleft  = int(float(xinterval.split(":")[1].split("-")[0]))
                plotright = int(float(xinterval.split(":")[1].split("-")[1]))
                plotwidth  = plotright - plotleft
                yscaf     = yinterval.split(":")[0]
                plotbottom  = int(float(yinterval.split(":")[1].split("-")[0]))
                plottop     = int(float(yinterval.split(":")[1].split("-")[1]))
                plotheight = plottop - plotbottom
                inxdf     = xranges_to_dfdict[xinterval]["in"]
                outxdf     = xranges_to_dfdict[xinterval]["out"]
                inydf     = yranges_to_dfdict[yinterval]["in"]
                outydf     = yranges_to_dfdict[yinterval]["out"]
                inX_inY   = len(inxdf.merge(inydf))
                inX_outY  = len(inxdf.merge(outydf))
                outX_inY  = len(outxdf.merge(inydf))
                outX_outY = len(outxdf.merge(outydf))
                table = [[inX_inY, outX_inY], [inX_outY, outX_outY]]
                oddsratio, pvalue = stats.fisher_exact(table, alternative="greater")
                fisher_dict.append({"xscaf": xscaf, "yscaf": yscaf,
                                    "inX_inY": inX_inY, "inX_outY": inX_outY,
                                    "outX_inY": outX_inY, "outX_outY": outX_outY,
                                    "oddsratio": oddsratio, "pvalue": pvalue,
                                    "plotleft": plotleft,
                                    "plotright": plotright,
                                    "plotwidth": plotwidth,
                                    "plotbottom": plotbottom,
                                    "plottop": plottop,
                                    "plotheight": plotheight})

    if style == "whole": # perform the analysis on whole chromosomes
        for xscaf in xorder: #Li
            for yscaf in yorder: #Wi
                #calculate the cells for fisher exact
                plotleft = x_offset[xscaf]
                plotright = x_offset[xscaf] + x_scaf_to_len[xscaf]
                plotwidth = plotright - plotleft
                plotbottom = y_offset[yscaf]
                plottop    = y_offset[yscaf] + y_scaf_to_len[yscaf]
                plotheight = plottop-plotbottom
                query = "yscaf == '{}' & xscaf == '{}'".format(yscaf, xscaf)
                inX_inY   = len(df.query(query))
                query = "yscaf == '{}' & xscaf != '{}'".format(yscaf, xscaf)
                inX_outY  = len(df.query(query))
                query = "yscaf != '{}' & xscaf == '{}'".format(yscaf, xscaf)
                outX_inY  = len(df.query(query))
                query = "yscaf != '{}' & xscaf != '{}'".format(yscaf, xscaf)
                outX_outY = len(df.query(query))
                table = [[inX_inY, outX_inY], [inX_outY, outX_outY]]
                oddsratio, pvalue = stats.fisher_exact(table, alternative="greater")
                fisher_dict.append({"xscaf": xscaf, "yscaf": yscaf,
                                    "inX_inY": inX_inY, "inX_outY": inX_outY,
                                    "outX_inY": outX_inY, "outX_outY": outX_outY,
                                    "oddsratio": oddsratio, "pvalue": pvalue,
                                    "plotleft": plotleft,
                                    "plotright": plotright,
                                    "plotwidth": plotwidth,
                                    "plotbottom": plotbottom,
                                    "plottop": plottop,
                                    "plotheight": plotheight})
    fisherdf = pd.DataFrame(fisher_dict)
    fisherdf.to_csv(outdf, sep="\t")

rule gen_fishertable_whole:
    """
    generates a table of fisher's exact test results for whole chromosomes
    output is a df that can be read back into pandas
    """
    input:
        dtable = "synteny_analysis/dvalue_table/{Asample}_and_{Dsample}_against_{BCsample}_info.tsv",
        plot_order = "synteny_analysis/plot_order/{Asample}_and_{Dsample}_against_{BCsample}_plotorder.tsv",
        ycoords = "synteny_analysis/genome_coords/BC_genome_coords/{BCsample}_genomecoords.txt",
        xcoords = "synteny_analysis/genome_coords/AD_genome_coords/{Asample}_and_{Dsample}_genomecoords.txt",
        xbreaks_manual = "synteny_analysis/dvalue_table_breaks/{Asample}_and_{Dsample}_against_{BCsample}_xbreaks_manual.tsv",
        ybreaks_manual = "synteny_analysis/dvalue_table_breaks/{Asample}_and_{Dsample}_against_{BCsample}_ybreaks_manual.tsv",
    output:
        fisherswhole   = "synteny_analysis/plots/significance/tables/{Asample}_and_{Dsample}_against_{BCsample}_fisher_wholechr.tsv"
    threads:
        1
    params:
        xsample  = lambda wildcards: "{}_and_{}".format(wildcards.Asample, wildcards.Dsample),
        ysample  = lambda wildcards: wildcards.BCsample,
        style    = "whole"
    run:
        fishers_exact(input.dtable,          input.plot_order,
                      input.xcoords,         input.ycoords,
                      params.xsample,        params.ysample,
                      input.xbreaks_manual,  input.ybreaks_manual,
                      output.fisherswhole,   params.style)

rule gen_fishertable_manualbreaks:
    """
    generates a table of fisher's exact test results for the manual breaks chromosomes
    output is a df that can be read back into pandas
    """
    input:
        dtable = "synteny_analysis/dvalue_table/{xsample}_and_{ysample}_info.tsv",
        ycoords = "synteny_analysis/genome_coords/y_genome_coords/{ysample}_genomecoords.txt",
        xcoords = "synteny_analysis/genome_coords/x_genome_coords/{xsample}_genomecoords.txt",
        xbreaks_manual = "synteny_analysis/dvalue_table_breaks/{xsample}_and_{ysample}_xbreaks_manual.tsv",
        ybreaks_manual = "synteny_analysis/dvalue_table_breaks/{xsample}_and_{ysample}_ybreaks_manual.tsv",
    output:
        fishersmanualbreaks   = "synteny_analysis/plots/significance/tables/{xsample}_and_{ysample}_fisher_manualbreaks.tsv"
    threads:
        1
    params:
        xsample = lambda wildcards: wildcards.xsample,
        ysample = lambda wildcards: wildcards.ysample,
        style   = "breaks",
    run:
        fishers_exact(input.dtable,
                      input.xcoords,         input.ycoords,
                      params.xsample,        params.ysample,
                      input.xbreaks_manual,  input.ybreaks_manual,
                      output.fishersmanualbreaks,   params.style)


def scale_pvalue_to_0_1(vector, reverse = False):
    """
    scales a value to between 0 and 1 given the min and max values seen in that vector

    we might pass the log, so log(0) = inf. Look for that as special case to define minp

    returns a vector
    """
    #first find max
    maxp = -99999999999999
    minp = 99999999999
    for entry in vector:
        if math.isinf(entry) or math.isnan(entry):
            pass
        elif entry < minp:
            minp = entry
        elif entry > maxp:
            maxp = entry
    # now scale everything to between 0 and 1
    outvec = []
    for entry in vector:
        corrected = entry
        if math.isinf(entry) or math.isnan(entry):
            corrected = sys.float_info.min
        thisval = (corrected-minp)/(maxp-minp)
        if reverse:
            outvec.append(1-thisval)
        else:
            outvec.append(thisval)
    return outvec

def correlation_plot(plotting_df, fishertsv, plot_order,
                     xcoords_file, ycoords_file,
                     xsample,      ysample,
                     xbreaks_file, ybreaks_file,
                     densityplot, style, autoscale_color):
    """
    correlation plot makes a plot of the Fisher's exact test for each chromosome

    The style variable can be:
      - "whole_dots"
      - "whole_colors"
      - "breaks"
    """
    xorder = []
    yorder = []
    inx = False
    iny = False
    # load up the plotting order
    with open(plot_order, "r") as f:
        for line in f:
            line = line.strip()
            if line:
                if line == "xplotorder:":
                    inx = True
                    iny = False
                elif line == "yplotorder:":
                    inx = False
                    iny = True
                else:
                    entry = line.split(" ")[-1]
                    if inx:
                        xorder.append(entry)
                    elif iny:
                        yorder.append(entry)
    col_name = "scaf"
    # first we load up the x-axis coords and the ycoords
    xcoords_df = pd.read_csv(xcoords_file, delimiter=" ", header = None)
    xcoords_df.columns = ["scaf", "length", "stop", "start"]
    xcoords_df = xcoords_df.drop(["stop", "start"], axis = 1)
    xcoords_df = xcoords_df[xcoords_df["scaf"].isin(xorder)]
    # Create a dummy df with the required list and the col name to sort on
    dummy = pd.Series(xorder, name = col_name).to_frame()
    # Use left merge on the dummy to return a sorted df
    xcoords_df = dummy.merge(xcoords_df, on = col_name, how = "left")
    xcoords_df = xcoords_df.dropna()
    xcoords_df["start"]  = xcoords_df["length"].cumsum() - xcoords_df["length"]
    xcoords_df["stop"]   = xcoords_df["length"].cumsum()
    xcoords_df["middle"] = xcoords_df["start"] + (xcoords_df["stop"] - xcoords_df["start"])/2

    ycoords_df = pd.read_csv(ycoords_file, delimiter=" ", header = None)
    ycoords_df.columns = ["scaf", "length", "stop", "start"]
    ycoords_df = ycoords_df.drop(["stop", "start"], axis = 1)
    ycoords_df = ycoords_df[ycoords_df["scaf"].isin(yorder)]
    # Create a dummy df with the required list and the col name to sort on
    dummy = pd.Series(yorder, name = col_name).to_frame()
    # Use left merge on the dummy to return a sorted df
    ycoords_df = dummy.merge(ycoords_df, on = col_name, how = "left")
    ycoords_df = ycoords_df.dropna()
    ycoords_df["start"] = ycoords_df["length"].cumsum() - ycoords_df["length"]
    ycoords_df["stop"]  = ycoords_df["length"].cumsum()
    ycoords_df["middle"] = ycoords_df["start"] + (ycoords_df["stop"] - ycoords_df["start"])/2
    x_offset      = dict(zip(xcoords_df.scaf, xcoords_df.start))
    x_scaf_to_len = dict(zip(xcoords_df.scaf, xcoords_df.length))
    y_offset      = dict(zip(ycoords_df.scaf, ycoords_df.start))
    y_scaf_to_len = dict(zip(ycoords_df.scaf, ycoords_df.length))

    gray   = "#d1cbcc"
    yellow = "#f3e056"
    orange = "#f98e08"
    red    = "#7d1d6c"
    from scipy import stats
    import seaborn as sns; sns.set()
    import matplotlib
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.ticker import StrMethodFormatter, NullFormatter
    from matplotlib import cm
    from matplotlib.colors import ListedColormap, LinearSegmentedColormap
    # set seaborn stuff
    #sns.set(rc={'text.usetex' : True})
    sns.set_style("ticks", {'font.family': ['sans-serif'],
                                'font.sans-serif': ['Helvetica'],
                                'grid.color': '.95'})
    # Preserve the vertical order of embedded images:
    matplotlib.rcParams['image.composite_image'] = False
    # text as font in pdf
    matplotlib.rcParams['pdf.fonttype'] = 42
    matplotlib.rcParams['ps.fonttype'] = 42

    # open the xbreaks and the ybreaks dataframes
    # These are where there are low-opacity,
    #  dotted lines to show breaks in synteny
    # example entries are like this:
    xbreaks_df = pd.read_csv(xbreaks_file, delimiter="\t", index_col=0)
    ybreaks_df = pd.read_csv(ybreaks_file, delimiter="\t", index_col=0)

    # first make a lookup table of how to calculate the
    #  x and y coords. This lookup is just the amount of
    # bp to add to the value when plotting. We pass the xprot_to_loc,
    #  xprot_to_scaf in case we need to sort everything based on order of
    #  occurrence on the scaffolds

    # first make a lookup table
    df       = pd.read_csv(plotting_df, delimiter="\t", index_col=0)
    fisherdf = pd.read_csv(fishertsv, delimiter="\t", index_col=0)
    fisherdf["pval01"] = scale_pvalue_to_0_1(fisherdf["pvalue"], reverse = False)
    print(fisherdf["pval01"])
    fisherdf["pval01_rev"] = scale_pvalue_to_0_1(fisherdf["pvalue"], reverse = True)
    fisherdf["pval01_log"] = scale_pvalue_to_0_1(np.log(fisherdf["pvalue"]), reverse = False)
    fisherdf["pval01_log_rev"] = scale_pvalue_to_0_1(np.log(fisherdf["pvalue"]), reverse = True)

    print("Performed {} tests".format(len(fisherdf)))
    print("0.05 equivalent for {} tests is {}".format(len(fisherdf), 0.05/len(fisherdf)))
    p_value_dict = {x: x/len(fisherdf) for x in [0.05, 0.00005, 0.00000005]}
    p_value_to_color = {0.05:       yellow,
                        0.00005:    orange,
                        0.00000005: red}
    fisherdf["color"] = gray
    # now add colors to each entry in the dataframe
    for index, row in fisherdf.iterrows():
        thisp      = row["pvalue"]
        min_vals   = [key for key in p_value_dict if thisp <= p_value_dict[key]]
        if len(min_vals) > 0:
            this_color = p_value_to_color[min(min_vals)]
            fisherdf.loc[index, "color"] = this_color
    for key in p_value_dict:
        subdf = fisherdf.loc[fisherdf["pvalue"] < p_value_dict[key], ]
        print("There are {} cells with pvalues below the {} Bf-corrected pvalue, {}".format(
            len(subdf), key, p_value_dict[key]))
    # figure out the widths of the cells to find the optimal dot size
    widths = []
    #for this_list in [horizontal_lines_at, vertical_lines_at
    for this_list in [list(sorted(x_offset.values()))]:
        for i in range(len(this_list)-1):
            widths.append(this_list[i+1]-this_list[i])
    x_median_size = statistics.median(sorted(widths))
    x_median_size = np.percentile(sorted(widths), 85)
    max_x = max(x_offset.values())
    max_y = max(y_offset.values())
    y_median_size = (x_median_size/max_x)*max_y

    # now make a scatter plot
    figWidth = 8
    figHeight = 8
    plt.figure(figsize=(figWidth,figHeight))
    #set the panel dimensions
    panelWidth = 4
    panelHeight = 4
    dpanel_width = 0.25
    #find the margins to center the panel in figure
    leftMargin = (figWidth - panelWidth)/2
    bottomMargin = ((figHeight - panelHeight)/2)
    panel1 = plt.axes([leftMargin/figWidth, #left
                         bottomMargin/figHeight,    #bottom
                         panelWidth/figWidth,   #width
                         panelHeight/figHeight])     #height
    panel1.tick_params(axis='both',which='both',
                        bottom=False, labelbottom=True,
                        left=False, labelleft=True,
                        right=False, labelright=False,
                        top=False, labeltop=False)
    panelleg = plt.axes([(leftMargin+panelWidth + 0.1)/figWidth, #left
                         bottomMargin/figHeight,    #bottom
                         (dpanel_width*4)/figWidth,   #width
                         panelHeight/figHeight])     #height
    panelleg.tick_params(axis='both',which='both',
                        bottom=False, labelbottom=False,
                        left=False, labelleft=False,
                        right=False, labelright=False,
                        top=False, labeltop=False)
    smallest_p = min(fisherdf["pvalue"])
    if style in ["whole_colors", "breaks"]:
        magma = cm.get_cmap("magma", 8)
        #magma = cm.get_cmap('magma', 8)
        #newcolors = magma(np.linspace(0, 1, 12))
        #white = np.array([256/256, 256/256, 256/256, 1])
        #newcolors[:5, :] = white
        #newcmp = ListedColormap(newcolors)
        for index, row in fisherdf.iterrows():
            left   = row["plotleft"]
            bottom = row["plotbottom"]
            width  = row["plotwidth"]
            height = row["plotheight"]
            if autoscale_color:
                rgba = magma(row["pval01_log"])
                rectangle = matplotlib.patches.Rectangle((left, bottom), width, height,
                                                  linewidth=0,
                                                  facecolor=rgba,
                                                  edgecolor="black", zorder = 2)
            else:
                rectangle = matplotlib.patches.Rectangle((left, bottom), width, height,
                                                  linewidth=0,
                                                  facecolor=row["color"],
                                                  edgecolor="black", zorder = 2)
            panel1.add_patch(rectangle)

    # set the panel linewidth thinner
    for this_panel in [panel1]:
        for axis in ['top','bottom','left','right']:
            this_panel.spines[axis].set_linewidth(0.5)

    # remove spines on legend
    for this_panel in [panelleg]:
        for axis in ['top','bottom','left','right']:
            this_panel.spines[axis].set_visible(False)

    # set mins and max
    xmax = xcoords_df["stop"].iloc[-1]
    ymax = ycoords_df["stop"].iloc[-1]
    panel1.set_xlim([0,xmax])
    panel1.set_ylim([0,ymax])
    xscalar = (dpanel_width*4)/panelWidth
    panelleg.set_xlim([0,xmax*xscalar]) # percent
    panelleg.set_ylim([0,ymax])

    # now plot the legend
    # there are 6 sizes to plot
    # take up the top 1/3 of the panel
    if (("whole" in style) or (style == "breaks")):
        legend_bottom_y = ymax - int(ymax/3)
        legend_top_y    = ymax
        leg_y_seglen        = int(ymax/3/7)
        # set the points 15% away from left edge
        leg_x_offset        = 0.15 * (xmax*xscalar)
        leg_x_pos_ellipse = [leg_x_offset]*6
        leg_y_pos_ellipse = [legend_top_y - leg_y_seglen]
        for i in range(4):
            leg_y_pos_ellipse.append(leg_y_pos_ellipse[-1] - leg_y_seglen)
        # now actually plot the ellipses
        legscale, legsize = sizes_and_scale_minp(smallest_p)
        legscale.append(0.15)
        legsize.append("1")
        index_to_color = [gray, yellow, orange, red]
        index_to_text  = ["> 0.05", "< 0.05", "< 5e-4", "< 5e-7"]
        for i in range(4):
            x = x_median_size/2
            y = y_median_size/2
            circ = matplotlib.patches.Ellipse(
                       (leg_x_pos_ellipse[i], leg_y_pos_ellipse[i]),
                       x, y, ec = None, linewidth = None, color=index_to_color[i])
            panelleg.add_patch(circ)
            textx = leg_x_pos_ellipse[i] + leg_x_offset
            texty = leg_y_pos_ellipse[i]
            s = "{}".format(index_to_text[i])
            matplotlib.pyplot.text(textx, texty, s, ha="left", va = "center", fontsize = 8)

    # set x ticks
    xtickpos   = xcoords_df["middle"]
    xticklabel = xcoords_df["scaf"]
    xoffset    = xcoords_df["start"]
    xend       = xcoords_df["stop"]
    panel1.set_xticks(xtickpos)
    panel1.set_xticklabels(xticklabel, fontsize=8, rotation = 90)
    panel1.set_xlabel(xsample + " scaffolds")

    # set y ticks
    ytickpos   = ycoords_df["middle"]
    yticklabel = ycoords_df["scaf"]
    yoffset    = ycoords_df["start"]
    yend       = ycoords_df["stop"]
    panel1.set_yticks(ytickpos)
    panel1.set_yticklabels(yticklabel, fontsize=8)
    panel1.set_ylabel(ysample + " scaffolds")

    for this_axis in [panel1]:
        this_axis.xaxis.get_offset_text().set_visible(False)
        this_axis.yaxis.get_offset_text().set_visible(False)

    #plot vertical lines
    for value in xoffset[1:]:
        panel1.axvline(x=value, color="black", lw=0.5)
    #plot horizontal lines
    for value in yoffset[1:]:
        panel1.axhline(y=value, color="black", lw=0.5)


    plt.savefig(densityplot)


rule plot_fishers_whole_color_cells:
    """
    Plots the correlation matrices of the whole scaffolds.
      - Colors in the whole cells.
    """
    input:
        dtable = "synteny_analysis/dvalue_table/{Asample}_and_{Dsample}_against_{BCsample}_info.tsv",
        plot_order = "synteny_analysis/plot_order/{Asample}_and_{Dsample}_against_{BCsample}_plotorder.tsv",
        fishertsv   = "synteny_analysis/plots/significance/tables/{Asample}_and_{Dsample}_against_{BCsample}_fisher_wholechr.tsv",
        ycoords = "synteny_analysis/genome_coords/BC_genome_coords/{BCsample}_genomecoords.txt",
        xcoords = "synteny_analysis/genome_coords/AD_genome_coords/{Asample}_and_{Dsample}_genomecoords.txt",
        xbreaks_manual = "synteny_analysis/dvalue_table_breaks/{Asample}_and_{Dsample}_against_{BCsample}_xbreaks_manual.tsv",
        ybreaks_manual = "synteny_analysis/dvalue_table_breaks/{Asample}_and_{Dsample}_against_{BCsample}_ybreaks_manual.tsv",
    output:
        density_plot   = "synteny_analysis/plots/significance/wholechr_colors/{Asample}_and_{Dsample}_against_{BCsample}_fisher_chromcolor.pdf"
    threads:
        1
    params:
        xsample  = lambda wildcards: "{}_and_{}".format(wildcards.Asample, wildcards.Dsample),
        ysample  = lambda wildcards: wildcards.BCsample,
        style   = "whole_colors",
        autoscale = False
    run:
        correlation_plot(input.dtable,          input.fishertsv, input.plot_order,
                         input.xcoords,         input.ycoords,
                         params.xsample,        params.ysample,
                         input.xbreaks_manual,  input.ybreaks_manual,
                         output.density_plot,   params.style, params.autoscale)

#rule plot_fishers_manualbreaks:
#    """
#    Plots the correlation matrices of the whole scaffolds.
#      - Colors in the automatic breaks
#    """
#    input:
#        dtable = "synteny_analysis/dvalue_table/{xsample}_and_{ysample}_info.tsv",
#        fishertsv   = "synteny_analysis/plots/significance/tables/{xsample}_and_{ysample}_fisher_manualbreaks.tsv",
#        ycoords = "synteny_analysis/genome_coords/y_genome_coords/{ysample}_genomecoords.txt",
#        xcoords = "synteny_analysis/genome_coords/x_genome_coords/{xsample}_genomecoords.txt",
#        #xbreaks_auto = "synteny_analysis/dvalue_table_breaks/{xsample}_and_{ysample}_xbreaks_manual.tsv",
#        #ybreaks_auto = "synteny_analysis/dvalue_table_breaks/{xsample}_and_{ysample}_ybreaks_manual.tsv",
#        xbreaks_manual = "synteny_analysis/dvalue_table_breaks/{xsample}_and_{ysample}_xbreaks_manual.tsv",
#        ybreaks_manual = "synteny_analysis/dvalue_table_breaks/{xsample}_and_{ysample}_ybreaks_manual.tsv",
#    output:
#        density_plot   = "synteny_analysis/plots/significance/breaks/{xsample}_and_{ysample}_fisher_manualbreaks.pdf"
#    threads:
#        1
#    params:
#        xsample = lambda wildcards: wildcards.xsample,
#        ysample = lambda wildcards: wildcards.ysample,
#        style   = "breaks",
#        autoscale = False
#    run:
#        correlation_plot(input.dtable,          input.fishertsv,
#                         input.xcoords,         input.ycoords,
#                         params.xsample,        params.ysample,
#                         input.xbreaks_manual,  input.ybreaks_manual,
#                         output.density_plot,   params.style, params.autoscale)



#rule xprot_to_color:
#    """
#    In addition to plotting the synteny without a color scheme,
#      we also would like to plot by coloring with another species' color scheme
#    The output is just:
#    xsample_prot\thex_color
#    """
#    input:
#        x_prot_to_loc = lambda wildcards: config["xaxisspecies"][wildcards.colorby]["prot_to_loc"]
#    output:
#        prot_to_color = "synteny_analysis/prot_to_color/{colorby}_prottocolor.tsv"
#    params:
#        colormap = lambda wildcards: config["xaxisspecies"][wildcards.colorby]["chrom_to_color"]
#    run:
#        print(params.colormap)
#        # parse the printing information
#        print_list = []
#        for key in params.colormap:
#            coord = key
#            color = params.colormap[coord]
#            scaf = coord.split(":")[0]
#            pos_raw = coord.split(":")[1]
#            if pos_raw == "all":
#                pos_min = 1
#                pos_max = 999999999
#            else:
#                pos_min = int(pos_raw.split("-")[0])
#                pos_max = int(pos_raw.split("-")[1])
#            print_list.append({"scaf": scaf, "pos_min": pos_min,
#                               "pos_max": pos_max, "color": color})
#        df = pd.DataFrame.from_dict(print_list)
#        print(df)
#        #df["colors_py"] =  df["color"].apply(matplotlib.colors.to_rgba)
#        out_handle = open(output.prot_to_color, "w")
#        xstruct = generate_coord_structs_from_chrom_to_loc(input.x_prot_to_loc)
#        for prot in list(xstruct["prot_to_scaf"].keys()):
#            scaf = xstruct["prot_to_scaf"][prot]
#            if scaf in list(df["scaf"]):
#                pos  = xstruct["prot_to_middle"][prot]
#                query = "scaf == '{}' & pos_min <= {} & pos_max >= {}".format(scaf, pos, pos)
#                color = df.query(query)["color"].values[0]
#                print("{}\t{}".format(prot, color), file=out_handle)
#            else:
#                color = "#000000"
#                print("{}\t{}".format(prot, color), file=out_handle)
#        out_handle.close()
#
#"""
#This makes the plots where the proteins are colored by another protein set.
#
#Jan 12 2021 I am not sure what the no missing plot version is.
#
#For some reason I am getting an InputFunctionException
#"""
#rule plot_synteny_x_colored_by_x:
#    input:
#        dtable = "synteny_analysis/dvalue_table/{xsample}_and_{ysample}_info.tsv",
#        plot_order = "synteny_analysis/plot_order/{xsample}_and_{ysample}_plotorder.tsv",
#        ycoords = "synteny_analysis/genome_coords/y_genome_coords/{ysample}_genomecoords.txt",
#        xcoords = "synteny_analysis/genome_coords/x_genome_coords/{xsample}_genomecoords.txt",
#        xbreaks_auto = "synteny_analysis/dvalue_table_breaks/{xsample}_and_{ysample}_xbreaks_auto.tsv",
#        ybreaks_auto = "synteny_analysis/dvalue_table_breaks/{xsample}_and_{ysample}_ybreaks_auto.tsv",
#        xbreaks_manual = "synteny_analysis/dvalue_table_breaks/{xsample}_and_{ysample}_xbreaks_manual.tsv",
#        ybreaks_manual = "synteny_analysis/dvalue_table_breaks/{xsample}_and_{ysample}_ybreaks_manual.tsv",
#        xprottoloc = lambda wildcards: config["xaxisspecies"][wildcards.xsample]["prot_to_loc"],
#        yprottoloc = lambda wildcards: config["yaxisspecies"][wildcards.ysample]["prot_to_loc"],
#        color_by_blast = "synteny_analysis/blastp_results/reciprocal_best/{xsample}_and_{colorby}_recip.blastp",
#        color_by = "synteny_analysis/prot_to_color/{colorby}_prottocolor.tsv"
#    output:
#        synplot_auto = "synteny_analysis/plots/synteny_colored_by/{xsample}_and_{ysample}_coloredby_{colorby}_synteny_autobreaks.pdf",
#        nodots_auto = "synteny_analysis/plots/synteny_colored_by_no_missing/{xsample}_and_{ysample}_coloredby_{colorby}_synteny_autobreaks.pdf",
#        synplot_manual = "synteny_analysis/plots/synteny_colored_by/{xsample}_and_{ysample}_coloredby_{colorby}_synteny_manualbreaks.pdf",
#        nodots_manual = "synteny_analysis/plots/synteny_colored_by_no_missing/{xsample}_and_{ysample}_coloredby_{colorby}_synteny_manualbreaks.pdf",
#
#    threads:
#        1
#    params:
#        xsample = lambda wildcards: wildcards.xsample,
#        ysample = lambda wildcards: wildcards.ysample,
#        color_sample = lambda wildcards: wildcards.colorby,
#        keep_x   = lambda wildcards: False if ( ("sort_by_x_coord_blast" in config["xaxisspecies"][wildcards.xsample]) or ("noxlines" in config["xaxisspecies"][wildcards.xsample])) else True,
#        keep_y   = lambda wildcards: False if ( ("sort_by_x_coord_blast" in config["yaxisspecies"][wildcards.ysample]) or ("noylines" in config["yaxisspecies"][wildcards.ysample])) else True,
#    run:
#        print("printing x")
#        print(config["xaxisspecies"][wildcards.xsample])
#        #first figure out what the color should be for each protein pair
#        colorby_prot_to_color = {}
#        with open(input.color_by, "r") as f:
#            for line in f:
#                line = line.strip()
#                if line:
#                    splitd = line.split("\t")
#                    xprot = splitd[0]
#                    colorbyprot = splitd[1]
#                    colorby_prot_to_color[xprot] = colorbyprot
#        # now use the blast results to lookup the prot color
#        if params.xsample == params.color_sample:
#            print("x is the same as color")
#            prot_to_color = colorby_prot_to_color
#        else:
#            prot_to_color = {}
#            try_counter =0
#            fail_counter = 0
#            with open(input.color_by_blast, "r") as f:
#                for line in f:
#                    line = line.strip()
#                    if line:
#                        splitd = line.split("\t")
#                        try:
#                            prot_to_color[splitd[0]] = colorby_prot_to_color[splitd[1]]
#                            try_counter += 1
#                        except:
#                            prot_to_color[splitd[0]] = "#000000"
#                            fail_counter += 1
#            print(try_counter, fail_counter)
#        # now that we have the colors, plot
#          # auto breaks
#        synteny_plot(input.dtable,   input.xcoords,  input.ycoords,
#                     params.xsample, params.ysample,
#                     input.xbreaks_auto, input.ybreaks_auto,
#                     output.synplot_auto, prot_to_color,  False,
#                     plot_x_lines = params.keep_x,
#                     plot_y_lines = params.keep_y)
#          # manual breaks
#        synteny_plot(input.dtable,   input.xcoords,  input.ycoords,
#                     params.xsample, params.ysample,
#                     input.xbreaks_manual, input.ybreaks_manual,
#                     output.synplot_manual, prot_to_color,  False,
#                     plot_x_lines = params.keep_x,
#                     plot_y_lines = params.keep_y)
#
#
#        # plot again, but without the black (missing) points
#          # auto breaks
#        synteny_plot(input.dtable,   input.xcoords,  input.ycoords,
#                     params.xsample, params.ysample,
#                     input.xbreaks_auto, input.ybreaks_auto,
#                     output.nodots_auto, prot_to_color,  True,
#                     plot_x_lines = params.keep_x,
#                     plot_y_lines = params.keep_y)
#          # manual breaks
#        synteny_plot(input.dtable,   input.xcoords,  input.ycoords,
#                     params.xsample, params.ysample,
#                     input.xbreaks_manual, input.ybreaks_manual,
#                     output.nodots_manual, prot_to_color,  True,
#                     plot_x_lines = params.keep_x,
#                     plot_y_lines = params.keep_y)
