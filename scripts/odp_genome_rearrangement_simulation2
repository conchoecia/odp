"""
This script takes the rbh hits file, specifically of a 4-way rbh search,
  and mutates one group to match the number of chromosomes of another group.

This program considers the chromosome-scale genomes of four species,
with one known outgroup species. The program assumes the other three species
are a polytomy.

      ,========= outer
    =={
      {  ,====== species1
      '=={
         {====== species2
         {
         '====== species3

Using fusion-with-mixing events, the program looks for support for these three
possible phylogenetic topologies:

      hypothesis 1               hypothesis 2               hypothesis 3

     ,========= outer           ,========= outer           ,========= outer
   =={                        =={                        =={
     {  ,====== species1        {  ,====== species2        {  ,====== species3
     '=={                 OR    '=={                 OR    '=={
        {  ,=== species2           {  ,=== species1           {  ,=== species1
        '=={                       '=={                       '=={
           '=== species3              '=== species3              '=== species2


The config file will look something like this:

```
# this parameter is the rbh file you will use to look for groups
rbh_file: "EMU_HCA_RESLi_SRO_reciprocal_best_hits.rbh"
outer:  "SRO"
species1: "HCA"
species2: "EMU"
species3: "RESLi"

# This is the decay simulation.
num_swaps: 5000 # around 7 miniutes
num_simulations: 5000

# Randomization trials. Should be divisible by 100,000
# Each of the four genomes will be randomized in this many trials
num_randomizations:  1000000
```

"""

# data stuff
import pandas as pd
import numpy as np
# sequence stuff
from Bio import SeqIO
from Bio import SeqRecord
from Bio import Seq
# simulation stuff
import time
import random
from random import randrange
import sys
# plotting stuff
import ast
import itertools
import matplotlib.pyplot as plt
import matplotlib.patches as mplpatches
from matplotlib.collections import LineCollection
from matplotlib.colors import ListedColormap, LinearSegmentedColormap
from matplotlib.backends.backend_pdf import PdfPages
import matplotlib.pylab as pl
import operator

configfile: "config.yaml"

config["tool"] = "odp_genome_mutation_analysis"

#OdpF.check_legality(config)

# make sure the appropriate fields are present
check_these = ["rbh_file",
               "outgroup",
               "species1",
               "species2",
               "species3",
               "num_simulations",
               "species"]
for check_this in check_these:
    if not check_this in config:
        raise IOError("You must specify '{}' in config".format(check_this))

# make sure that the group fields are present
check_these = ["outgroup",
               "species1",
               "species2",
               "species3"]
for check_this in check_these:
    if config[check_this] not in config["species"]:
        raise IOError("The sample {} is not in the species".format(config[check_this]))

# randomizations
num_randomizations_per_round=10000
num_rand_rounds = int(config["num_randomizations"]/num_randomizations_per_round)
#print("number of randomization rounds is : {}".format(num_rand_rounds))

# make sure none of the sample names have underscores
for thissample in config["species"]:
    if "_" in thissample:
        raise IOError("Sample names can't have '_' char: {}".format(thissample))

four_species = [config["outgroup"],
                config["species1"],
                config["species2"],
                config["species3"]]
spstring = "-".join(four_species)

# check that the four species are present in the dataframe
tempdf = pd.read_csv(config["rbh_file"], index_col = None, sep = "\t")
for thisspecies in four_species:
    if "{}_scaf".format(thisspecies) not in tempdf.columns:
        raise IOError("Species {} was one of the defined species, but wasn't in the provided rbh file".format(thisspecies))
for thisspecies in [x.replace("_scaf", "") for x in tempdf.columns if x.endswith("_scaf")]:
    if thisspecies not in four_species:
        raise IOError("Species {} was in the rbh file, but wasn't in the specified species for this analysis.".format(thisspecies))

rule all:
    input:
        # just check the data
        config["tool"] + "/sim_randomization/initialization/random_sim_init.txt",
        config["tool"] + "/sim_randomization/initialization/groups_supporting_sp1_sister.txt",
        config["tool"] + "/sim_randomization/initialization/groups_supporting_sp2_sister.txt",
        config["tool"] + "/sim_randomization/initialization/groups_supporting_sp3_sister.txt",
        config["tool"] + "/sim_randomization/initialization/df_of_groups_supporting_sp1_sister.txt",
        config["tool"] + "/sim_randomization/initialization/df_of_groups_supporting_sp2_sister.txt",
        config["tool"] + "/sim_randomization/initialization/df_of_groups_supporting_sp3_sister.txt",

        expand(config["tool"] + "/sim_randomization/{species}/random_sim_{species}_{randcore}.txt",
               randcore = list(range(1, num_rand_rounds+1) ),
               species  = four_species),
        # plots
        expand("odp_genome_mutation_analysis/figures/{spstr}_randomization_marginals_{species}-randomizations.pdf",
               spstr = spstring, species = four_species),
        expand("odp_genome_mutation_analysis/figures/{spstr}_randomization_stats_{species}-randomizations.txt",
               spstr = spstring, species = four_species),
        expand("odp_genome_mutation_analysis/figures/{spstr}_support_{species}-randomizations.pdf",
               spstr = spstring, species = four_species)

def flatten3(li):
    """
    flattens nested lists
    """
    flatten = []
    for i in li:
        for ii in i:
            for iii in ii:
                flatten.append(iii)
    return flatten

def overlaps(x, y):
    """
    from https://stackoverflow.com/questions/64745139/check-if-two-integer-ranges-overlap
    """
    return max(x[0],y[0]) <= min(x[1],y[1])

def _get_groups_supporting_hypothesis(grouped_df,
                                      outgroup, speciesA,
                                      speciesB,
                                      speciesC):
    """
    Takes a df of potentially informative relationships and looks for
     phylogenetic support of this tree:

              ,========= outer
            =={
              {  ,====== speciesA
              '=={
                 {  ,=== speciesB
                 '=={
                    '=== speciesC

    Just returns a dataframe of the groupings that support this
     hypothesis

     This data structure: [[5,14], [7,10,5], [8,12]]
       - shows that there are three pairings of FLGs that support this hypothesis
       - the pairings have 5 and 14 genes, 7 and 10 and 5, 8 and 12 genes...
    """
    informative = grouped_df.groupby(["{}_scaf".format(speciesB), "{}_scaf".format(speciesC)]).filter(lambda x: len(x) >= 2)
    informative = informative.sort_values(["{}_scaf".format(speciesC),
                                           "{}_scaf".format(speciesB),
                                           "{}_scaf".format(speciesA),
                                           "{}_scaf".format(outgroup)]).reset_index(drop=True)

    # test hypothesis1
    hypAdf = informative.groupby(["{}_scaf".format(speciesB),
                                  "{}_scaf".format(speciesC)])
    #print(hypAdf.agg(list).reset_index(drop=True))
    #sys.exit()

    keeps = []
    for group_name, df_group in hypAdf:
        # Remove the entries where the outgroup has two of the same scaf.
        # These are derived splits in species1.
        subgroup = df_group.groupby(["{}_scaf".format(outgroup),
                                     "{}_scaf".format(speciesB),
                                     "{}_scaf".format(speciesC)
                                       ]).filter(lambda x: len(x) < 2)

        # This gets rid of cases where species1 has two of the same scaf.
        # These are cases where we're not sure whether the outer split
        #  is derived in the outer group or a merge in the ancestor of
        #  species1, species2, and inner.
        subgroup = subgroup.groupby(["{}_scaf".format(speciesA),
                                     "{}_scaf".format(speciesB),
                                     "{}_scaf".format(speciesC)
                                     ]).filter(lambda x: len(x) < 2)

        #print("len of subgroup is", len(subgroup))
        # make sure that the ranges of the genes overlap for mixing
        overlapping = False
        if len(subgroup) > 1:
            for thissp in [speciesB, speciesC]:
                # get a list of ranges of the extent of genes in the groups
                ranges_list = []
                for index in subgroup.index:
                    unwrapped  = subgroup.loc[index, "{}_pos".format(thissp)]
                    unwrapped2 = subgroup.loc[index, "{}_pos".format(thissp)]
                    if type(unwrapped) == str:
                        print("string", unwrapped)
                        pass
                    elif type(unwrapped) in [list, tuple]:
                        everything_int = True
                        for x in unwrapped:
                            if type(x) not in [int, float]:
                                everything_int = False
                        if everything_int:
                           # if  everything here is an int, then we're OK
                           # The list is OK and can be processed
                            unwrapped2 = [int(x) for x in unwrapped]
                        else:
                            # If there are things that aren't ints they're probably
                            # a multi=nested list
                            unwrapped2 = []
                            for i in unwrapped:
                                if type(i) == str:
                                    for ii in i.split(","):
                                        unwrapped2.append(int(ii))
                                else:
                                    raise IOError("The type here is {}, but we only know how to handle strings.".format(
                                        type(i)))
                    else:
                        raise IOError("Not sure how to handle this. Contact the developer.")
                    thismin = int(min(unwrapped2))
                    thismax = int(max(unwrapped2))
                    ranges_list.append([thismin, thismax])
                # now make sure at least two of the groups have overlapped
                for i in range(len(ranges_list)):
                    for j in range(i+1, len(ranges_list)):
                        if overlaps(ranges_list[i], ranges_list[j]):
                            overlapping = True

        if (len(subgroup) > 1) and overlapping:
            #print("keeps")
            #print(subgroup)
            keeps.append(subgroup)

    if len(keeps) > 0:
        hypAdf = pd.concat(keeps)
        hypAdf_grouped = hypAdf.groupby(["{}_scaf".format(speciesB),
                                         "{}_scaf".format(speciesC),
                                        ]).agg(list).reset_index()
    else:
        hypAdf = pd.DataFrame(columns = informative.columns)
        hypAdf_grouped = pd.DataFrame(columns = informative.columns)

    return hypAdf,hypAdf_grouped

def stats_on_df(df,
                outgroup, species1,
                species2, species3):
    """
    This calculates some statistics about the dataframe.
    All it records is the number of genes in the FLG pairs:

     This data structure: [[5,14], [7,10,5], [8,12]]
       - shows that there are three pairings of FLGs that support this hypothesis
       - the pairings have 5 and 14 genes, 7 and 10 and 5, 8 and 12 genes...

    The output is two columns:
    - column1: df of groups supporting sp1 as sister
    - column2: "" supporting sp2 as sister
    - column3: "" support sp3 as sister
    - column4: counts supporting hyp1 data structure
    - column5: counts supporting hyp2 data structure
    - column6: counts supporting hyp3 data structure
    - column7: rbh groups supporting sp1 as sister clade
    - column8: rbh groups supporting sp2 as sister clade
    - column9: rbh groups supporting sp3 as sister clade
    """
    gene_cols = ["{}_gene".format(x)
                 for x in [outgroup, species1, species2, species3] ]
    scaf_cols = ["{}_scaf".format(x)
                 for x in [outgroup, species2, species1, species3] ]
    grouped_multiple = df.groupby(scaf_cols).agg(list).reset_index()
    # get the size
    grouped_multiple["count"] = grouped_multiple.rbh.str.len()
    grouped_multiple = grouped_multiple.loc[grouped_multiple["count"] > 4, ]
    #grouped_multiple = grouped_multiple.sort_values(["{}_scaf".format(species3),
    #                                            "{}_scaf".format(species1),
    #                                            "{}_scaf".format(species2),
    #                                            "{}_scaf".format(outgroup)]).reset_index(drop=True)
    ## sort
    #grouped_multiple = grouped_multiple[scaf_cols + ["rbh", "count"]]

    r1_df, r1 = _get_groups_supporting_hypothesis(grouped_multiple, outgroup, species1, species2, species3)
    r2_df, r2 = _get_groups_supporting_hypothesis(grouped_multiple, outgroup, species2, species1, species3)
    r3_df, r3 = _get_groups_supporting_hypothesis(grouped_multiple, outgroup, species3, species1, species2)
    #print("r1", "\n", r1)
    #print("r2", "\n", r2)
    #print("r3", "\n", r3)

    return [r1_df, r2_df, r3_df,
            list(r1["count"]),
            list(r2["count"]),
            list(r3["count"]),
            flatten3(list(r1["rbh"])),
            flatten3(list(r2["rbh"])),
            flatten3(list(r3["rbh"])),
            ]

# randomization simulation
rule randomization_simulation:
    """
    This rule performs the randomization simulation.
    It prints out the stats from each round onto a line.
    """
    input:
        rbh_file = config["rbh_file"],
    output:
        random_sim = config["tool"] + "/sim_randomization/{species}/random_sim_{species}_{randcore}.txt"
    threads: 1
    params:
        outgroup  = config["outgroup"],
        species1  = config["species1"],
        species2  = config["species2"],
        species3  = config["species3"],
        species = lambda wildcards: wildcards.species,
        num_rounds = num_randomizations_per_round
    run:
        # now we load up the rbh table
        outhandle = open(output.random_sim, "w")
        df = pd.read_csv(input.rbh_file, index_col = None, sep = "\t")
        scaf_cols = [x for x in df.columns if "_scaf" in x]
        pos_cols = [x for x in df.columns if "_pos" in x]
        df = df[['rbh'] + scaf_cols + pos_cols]

        # species1 col
        species1_col = "{}_scaf".format(params.species)

        # go until we say to stop
        # how many days for simulation
        start_time = time.time()
        counter = 1
        while True:
            # randomize the species1 column
            df[species1_col] = np.random.permutation(df[species1_col].values)
            #print(list(df[species1_col][0:10]))
            ssdone = False
            stats = stats_on_df(
                    df,
                    params.outgroup,
                    params.species1,
                    params.species2,
                    params.species3)
            print("{}\t{}\t{}".format(stats[3], stats[4],
                                      stats[5]), file = outhandle)

            # cleanup
            if counter % 10 == 0:
                elapsed = time.time() - start_time
                days,  rem       = divmod(elapsed, 86400)
                hours, rem       = divmod(rem, 3600)
                minutes, seconds = divmod(rem, 60)
                days = int(days)
                hours = int(hours)
                minutes = int(minutes)
                seconds = int(seconds)
                print("  Done with {} iterations. Time elapsed: {}d {}h {}m {}s. \r".format(
                    counter, days, hours, minutes, seconds ), end = "\r")
            if counter == params.num_rounds:
                break
            counter = counter + 1

        outhandle.close()

# randomization simulation
rule randomization_initialization:
    """
    This measures the initial state of the genome.
    """
    input:
        rbh_file = config["rbh_file"]
    output:
        random_sim  = config["tool"] + "/sim_randomization/initialization/random_sim_init.txt",
        species1sisdf = config["tool"] + "/sim_randomization/initialization/df_of_groups_supporting_sp1_sister.txt",
        species2sisdf = config["tool"] + "/sim_randomization/initialization/df_of_groups_supporting_sp2_sister.txt",
        species3sisdf = config["tool"] + "/sim_randomization/initialization/df_of_groups_supporting_sp3_sister.txt",
        species1sis = config["tool"] + "/sim_randomization/initialization/groups_supporting_sp1_sister.txt",
        species2sis = config["tool"] + "/sim_randomization/initialization/groups_supporting_sp2_sister.txt",
        species3sis = config["tool"] + "/sim_randomization/initialization/groups_supporting_sp3_sister.txt",
    threads: 1
    params:
        outgroup = config["outgroup"],
        species1 = config["species1"],
        species2 = config["species2"],
        species3 = config["species3"],
        num_rounds = num_rand_rounds
    run:
        # now we load up the rbh table
        df = pd.read_csv(input.rbh_file, index_col = None, sep = "\t")
        #scaf_cols = [x for x in df.columns if "_scaf" in x]
        #pos_cols =  [x for x in df.columns if "_pos" in x]
        #df = df[['rbh'] + scaf_cols + pos_cols]

        stats = stats_on_df(
            df,
            params.outgroup,
            params.species1,
            params.species2,
            params.species3)

        # print out the dataframes of groups that support each hypothesis
        stats[0].to_csv(output.species1sisdf, sep="\t", index = False)
        stats[1].to_csv(output.species2sisdf, sep="\t", index = False)
        stats[2].to_csv(output.species3sisdf, sep="\t", index = False)

        # print out the number of groups supporting each hypothesis
        outhandle = open(output.random_sim, "w")
        print("{}\t{}\t{}".format(stats[3], stats[4], stats[5]),
              file = outhandle)
        outhandle.close()

        # just print the group counts
        with open(output.species1sis, "w") as f:
            for x in stats[6]:
                print(x, file = f)
        with open(output.species2sis, "w") as f:
            for x in stats[7]:
                print(x, file = f)
        with open(output.species3sis, "w") as f:
            for x in stats[8]:
                print(x, file = f)

rule make_randomization_summary:
    """
    This reads in all of the randomization data and turns it into a plottable,
    machine-readable file.

    The goal is to only execute this once per randomization trial.

    Get these fields for each hypothesis:
      - max_number_of_genes_in_grouping
      - total_number_of_genes_in_FLGs
      - total_number_of_groupings
      - mean_number_of_genes_in_each_FLG
    """
    input:
        random_sim = config["tool"] + "/sim_randomization/{species}/random_sim_{species}_{randcore}.txt"
    output:
        sim_plot = "odp_genome_mutation_analysis/sim_randomization/plottable/{species}/random_sim_{species}_{randcore}_plottable.txt"
    run:
        outhandle = open(output.sim_plot, "w")
        with open(input.random_sim, "r") as f:
            for line in f:
                line = line.strip()
                if line:
                    fields = line.split("\t")
                    hyp1_data  = ast.literal_eval(fields[0])
                    hyp2_data  = ast.literal_eval(fields[1])
                    hyp3_data  = ast.literal_eval(fields[2])
                    hyp1_unwrapped = [item for sublist in hyp1_data
                                      for item in sublist]
                    hyp2_unwrapped = [item for sublist in hyp2_data
                                      for item in sublist]
                    hyp3_unwrapped = [item for sublist in hyp3_data
                                      for item in sublist]

                    hyp1_max_number_of_genes_in_single_FLG = 0
                    hyp1_max_number_of_genes_in_grouping   = 0
                    hyp1_total_number_of_genes_in_FLGs     = 0
                    hyp1_total_number_of_groupings         = 0
                    hyp1_mean_number_of_genes_in_FLGs      = 0

                    hyp2_max_number_of_genes_in_single_FLG = 0
                    hyp2_max_number_of_genes_in_grouping   = 0
                    hyp2_total_number_of_genes_in_FLGs     = 0
                    hyp2_total_number_of_groupings         = 0
                    hyp2_mean_number_of_genes_in_FLGs      = 0

                    hyp3_max_number_of_genes_in_single_FLG = 0
                    hyp3_max_number_of_genes_in_grouping   = 0
                    hyp3_total_number_of_genes_in_FLGs     = 0
                    hyp3_total_number_of_groupings         = 0
                    hyp3_mean_number_of_genes_in_FLGs      = 0

                    # max number of genes in single FLG
                    try:
                        hyp1_max_number_of_genes_in_single_FLG = max(hyp1_unwrapped)
                    except:
                        pass
                    try:
                        hyp2_max_number_of_genes_in_single_FLG = max(hyp2_unwrapped)
                    except:
                        pass
                    try:
                        hyp3_max_number_of_genes_in_single_FLG = max(hyp2_unwrapped)
                    except:
                        pass

                    # max number of genes in grouping
                    try:
                        hyp1_max_number_of_genes_in_grouping   = max(sum(x) for x in hyp1_data)
                    except:
                        pass
                    try:
                        hyp2_max_number_of_genes_in_grouping   = max(sum(x) for x in hyp2_data)
                    except:
                        pass
                    try:
                        hyp3_max_number_of_genes_in_grouping   = max(sum(x) for x in hyp3_data)
                    except:
                        pass

                    # total number of genes in FLGs
                    hyp1_total_number_of_genes_in_FLGs     = sum(hyp1_unwrapped)
                    hyp2_total_number_of_genes_in_FLGs     = sum(hyp2_unwrapped)
                    hyp3_total_number_of_genes_in_FLGs     = sum(hyp3_unwrapped)

                    # total number of groupings
                    hyp1_total_number_of_groupings         = len(hyp1_data)
                    hyp2_total_number_of_groupings         = len(hyp2_data)
                    hyp3_total_number_of_groupings         = len(hyp3_data)

                    # mean number of genes in FLGs
                    try:
                        hyp1_mean_number_of_genes_in_FLGs = sum(hyp1_unwrapped)/len(hyp1_unwrapped)
                    except:
                        pass
                    try:
                        hyp2_mean_number_of_genes_in_FLGs = sum(hyp2_unwrapped)/len(hyp2_unwrapped)
                    except:
                        pass
                    try:
                        hyp3_mean_number_of_genes_in_FLGs = sum(hyp3_unwrapped)/len(hyp3_unwrapped)
                    except:
                        pass

                    print("\t".join([str(x) for x in [
                           hyp1_max_number_of_genes_in_single_FLG,
                           hyp1_max_number_of_genes_in_grouping,
                           hyp1_total_number_of_genes_in_FLGs,
                           hyp1_total_number_of_groupings,
                           hyp1_mean_number_of_genes_in_FLGs,
                           hyp2_max_number_of_genes_in_single_FLG,
                           hyp2_max_number_of_genes_in_grouping,
                           hyp2_total_number_of_genes_in_FLGs,
                           hyp2_total_number_of_groupings,
                           hyp2_mean_number_of_genes_in_FLGs,
                           hyp3_max_number_of_genes_in_single_FLG,
                           hyp3_max_number_of_genes_in_grouping,
                           hyp3_total_number_of_genes_in_FLGs,
                           hyp3_total_number_of_groupings,
                           hyp3_mean_number_of_genes_in_FLGs
                                                     ]
                                     ]),
                                     file = outhandle)
        outhandle.close()

rule cat_together_randomization_plottables:
    """
    This just cats together all the plottables into a single file
    so we can easily load it into seaborn later
    """
    input:
        sim_plot = expand("odp_genome_mutation_analysis/sim_randomization/plottable/{{species}}/random_sim_{{species}}_{randcore}_plottable.txt",
               randcore = list(range(1, num_rand_rounds+1) ),
               species = four_species)
    output:
        outfile = "odp_genome_mutation_analysis/sim_randomization/plottable_final/random_sim_final_plottable_{species}.txt"
    shell:
        """
        echo "" | awk '{{printf("hyp1_max_number_of_genes_in_single_FLG\\thyp1_max_number_of_genes_in_grouping\\thyp1_total_number_of_genes_in_FLGs\\thyp1_total_number_of_groupings\\thyp1_mean_number_of_genes_in_FLGs\\thyp2_max_number_of_genes_in_single_FLG\\thyp2_max_number_of_genes_in_grouping\\thyp2_total_number_of_genes_in_FLGs\\thyp2_total_number_of_groupings\\thyp2_mean_number_of_genes_in_FLGs\\thyp3_max_number_of_genes_in_single_FLG\\thyp3_max_number_of_genes_in_grouping\\thyp3_total_number_of_genes_in_FLGs\\thyp3_total_number_of_groupings\\thyp3_mean_number_of_genes_in_FLGs\\n")}}' > {output.outfile}
        cat {input.sim_plot} >> {output.outfile}
        """

rule plottable_init_file:
    """
    just make the initial measurement of the data plottable
    """
    input:
        init = "odp_genome_mutation_analysis/sim_randomization/initialization/random_sim_init.txt"
    output:
        init = "odp_genome_mutation_analysis/sim_randomization/initialization/random_sim_init_plottable.txt"
    run:
        # get the info for the init data
        hyp1_max_number_of_genes_in_single_FLG = 0
        hyp1_max_number_of_genes_in_grouping   = 0
        hyp1_total_number_of_genes_in_FLGs     = 0
        hyp1_total_number_of_groupings         = 0
        hyp1_mean_number_of_genes_in_FLGs      = 0

        hyp2_max_number_of_genes_in_single_FLG = 0
        hyp2_max_number_of_genes_in_grouping   = 0
        hyp2_total_number_of_genes_in_FLGs     = 0
        hyp2_total_number_of_groupings         = 0
        hyp2_mean_number_of_genes_in_FLGs      = 0

        hyp3_max_number_of_genes_in_single_FLG = 0
        hyp3_max_number_of_genes_in_grouping   = 0
        hyp3_total_number_of_genes_in_FLGs     = 0
        hyp3_total_number_of_groupings         = 0
        hyp3_mean_number_of_genes_in_FLGs      = 0

        with open(input.init, "r") as f:
            for line in f:
                line = line.strip()
                if line:
                    fields = line.split("\t")
                    hyp1_data  = ast.literal_eval(fields[0])
                    hyp2_data  = ast.literal_eval(fields[1])
                    hyp3_data  = ast.literal_eval(fields[2])
                    hyp1_unwrapped = [item for sublist in hyp1_data
                                      for item in sublist]
                    hyp2_unwrapped = [item for sublist in hyp2_data
                                      for item in sublist]
                    hyp3_unwrapped = [item for sublist in hyp3_data
                                      for item in sublist]

                    # max number of genes in single FLG
                    try:
                        hyp1_max_number_of_genes_in_single_FLG = max(hyp1_unwrapped)
                    except:
                        pass
                    try:
                        hyp2_max_number_of_genes_in_single_FLG = max(hyp2_unwrapped)
                    except:
                        pass
                    try:
                        hyp3_max_number_of_genes_in_single_FLG = max(hyp3_unwrapped)
                    except:
                        pass

                    # max number of genes in grouping
                    try:
                        hyp1_max_number_of_genes_in_grouping = max(sum(x) for x in hyp1_data)
                    except:
                        pass
                    try:
                        hyp2_max_number_of_genes_in_grouping = max(sum(x) for x in hyp2_data)
                    except:
                        pass
                    try:
                        hyp3_max_number_of_genes_in_grouping = max(sum(x) for x in hyp3_data)
                    except:
                        pass

                    # total number of genes in FLGs
                    hyp1_total_number_of_genes_in_FLGs = sum(hyp1_unwrapped)
                    hyp2_total_number_of_genes_in_FLGs = sum(hyp2_unwrapped)
                    hyp3_total_number_of_genes_in_FLGs = sum(hyp3_unwrapped)

                    # total number of groupings
                    hyp1_total_number_of_groupings = len(hyp1_data)
                    hyp2_total_number_of_groupings = len(hyp2_data)
                    hyp3_total_number_of_groupings = len(hyp3_data)

                    # mean number of genes in FLGs
                    try:
                        hyp1_mean_number_of_genes_in_FLGs = sum(hyp1_unwrapped)/len(hyp1_unwrapped)
                    except:
                        pass
                    try:
                        hyp2_mean_number_of_genes_in_FLGs = sum(hyp2_unwrapped)/len(hyp2_unwrapped)
                    except:
                        pass
                    try:
                        hyp3_mean_number_of_genes_in_FLGs = sum(hyp3_unwrapped)/len(hyp3_unwrapped)
                    except:
                        pass

        outhandle = open(output.init, "w")
        print("\t".join(["hyp1_max_number_of_genes_in_single_FLG",
                         "hyp1_max_number_of_genes_in_grouping",
                         "hyp1_total_number_of_genes_in_FLGs",
                         "hyp1_total_number_of_groupings",
                         "hyp1_mean_number_of_genes_in_FLGs",

                         "hyp2_max_number_of_genes_in_single_FLG",
                         "hyp2_max_number_of_genes_in_grouping",
                         "hyp2_total_number_of_genes_in_FLGs",
                         "hyp2_total_number_of_groupings",
                         "hyp2_mean_number_of_genes_in_FLGs",

                         "hyp3_max_number_of_genes_in_single_FLG",
                         "hyp3_max_number_of_genes_in_grouping",
                         "hyp3_total_number_of_genes_in_FLGs",
                         "hyp3_total_number_of_groupings",
                         "hyp3_mean_number_of_genes_in_FLGs",
                         ]),
              file = outhandle)
        print("\t".join([str(x) for x in [
                         hyp1_max_number_of_genes_in_single_FLG,
                         hyp1_max_number_of_genes_in_grouping,
                         hyp1_total_number_of_genes_in_FLGs,
                         hyp1_total_number_of_groupings,
                         hyp1_mean_number_of_genes_in_FLGs,

                         hyp2_max_number_of_genes_in_single_FLG,
                         hyp2_max_number_of_genes_in_grouping,
                         hyp2_total_number_of_genes_in_FLGs,
                         hyp2_total_number_of_groupings,
                         hyp2_mean_number_of_genes_in_FLGs,

                         hyp3_max_number_of_genes_in_single_FLG,
                         hyp3_max_number_of_genes_in_grouping,
                         hyp3_total_number_of_genes_in_FLGs,
                         hyp3_total_number_of_groupings,
                         hyp3_mean_number_of_genes_in_FLGs,
                      ]]),
              file = outhandle)
        outhandle.close()

rule plot_joint_clouds:
    """
    Makes density maps with marginal distribution plots.
    """
    input:
        data = "odp_genome_mutation_analysis/sim_randomization/plottable_final/random_sim_final_plottable_{species}.txt",
        init = "odp_genome_mutation_analysis/sim_randomization/initialization/random_sim_init_plottable.txt"
    output:
        pdf   = "odp_genome_mutation_analysis/figures/{spstr}_randomization_marginals_{species}-randomizations.pdf",
        stats = "odp_genome_mutation_analysis/figures/{spstr}_randomization_stats_{species}-randomizations.txt"
    run:
        import matplotlib.cm as cm
        outhandle = open(output.stats, "w")
        initdf = pd.read_csv(input.init, index_col = None, sep = "\t")
        print("# INIT STATS", file = outhandle)
        print(initdf.iloc[0], file=outhandle)
        print("", file = outhandle)

        df = pd.read_csv(input.data, index_col = None, sep = "\t")

        # just collect some basic stats
        print("# SIMULATION STATS", file = outhandle)
        print("total number of simulations: {}".format(len(df)), file = outhandle)
        print("minimum alpha: {}".format(1/len(df)), file = outhandle)
        print("", file = outhandle)

        # collect stats about each individual field
        print("# SINGLE VARIABLE STATS", file = outhandle)
        for thisfield in df.columns:
            initval = initdf.iloc[0][thisfield]
            tempdf = df.loc[df[thisfield] >= initval,]
            tempdf = tempdf.loc[tempdf[thisfield] != 0, ]
            print("Variable: {}".format(thisfield), file =outhandle)
            print("  - Num of simulations >= init's value of {}: {}".format(
                initval, len(tempdf)),
                  file = outhandle)
            if len(tempdf) == 0:
                print("  - alpha: too_low_to_measure",
                      file = outhandle)
            else:
                print("  - alpha: {}".format(len(tempdf)/len(df)),
                      file = outhandle)
        print("", file = outhandle)

        # print joint probabilities
        print("# TWO-VAR JOINT PROB", file = outhandle)
        for thishyp in ["hyp1", "hyp2", "hyp3"]:
            these = [x for x in df.columns if thishyp in x]
            combos = list(itertools.combinations(these, 2))
            for thiscombo in combos:
                field0 = thiscombo[0]
                field1 = thiscombo[1]
                initval0 = initdf.iloc[0][field0]
                initval1 = initdf.iloc[0][field1]
                tempdf = df.loc[df[field0] >= initval0, ]
                tempdf = tempdf.loc[tempdf[field0] != 0, ]
                tempdf = tempdf.loc[tempdf[field1] >= initval1, ]
                tempdf = tempdf.loc[tempdf[field1] != 0, ]
                print("Variables: {} and {}".format(field0, field1), file =outhandle)
                print("  - Num of simulations >= init's values of {} and {}: {}".format(
                    initval0, initval1, len(tempdf)),
                      file = outhandle)
                if len(tempdf) == 0:
                    print("  - alpha: too_low_to_measure",
                          file = outhandle)
                else:
                    print("  - alpha: {}".format(len(tempdf)/len(df)),
                          file = outhandle)
            print("", file = outhandle)
        print("", file = outhandle)

        import seaborn as sns
        sns.set_theme(style="ticks")

        # define custom colormap with fixed colour and alpha gradient
        # use simple linear interpolation in the entire scale
        cdict = {'red':   [(0.,0.,0),
                           (0.,0.,0)],

                 'green': [(0.,0.,0.),
                           (0.,0.,0.)],

                 'blue':  [(0.,0.,0.),
                           (0.,0.,0.)],

                 'alpha': [(1.,1,1),
                           (0.,0,0)]}

        cm.register_cmap(cmap=LinearSegmentedColormap("alpha_gradient", cdict))

        N = 256
        vals = np.ones((N, 4))
        vals[:, 0] = np.linspace(0, 0, N)
        vals[:, 1] = np.linspace(0, 0, N)
        vals[:, 2] = np.linspace(0, 0, N)
        vals[:, 3] = np.linspace(0, 1, N)
        newcmp = ListedColormap(vals)


        with PdfPages(output.pdf) as pdf_pages:
            possible_vars = list(set(["_".join(x.split("_")[1::]) for x in df.columns]))
            combos = list(itertools.combinations(possible_vars, 2))
            for thiscombo in combos:
                for thishyp in ["hyp1", "hyp2", "hyp3"]:

                    for orientation in [[thiscombo[0], thiscombo[1]],
                                        [thiscombo[1], thiscombo[0]]]:
                        initval0 = initdf.iloc[0]["{}_{}".format(thishyp, orientation[0])]
                        initval1 = initdf.iloc[0]["{}_{}".format(thishyp, orientation[1])]

                        # PLOTTING hyp1
                        field0 = "{}_{}".format(thishyp, orientation[0])
                        field1 = "{}_{}".format(thishyp, orientation[1])
                        tempdf = df[[field0, field1]]
                        tempdf = tempdf.drop_duplicates(
                            subset = [field0, field1]).reset_index(drop = True)

                        xmax = max(initval0, max(df[field0])) * 1.2
                        ymax = max(initval1, max(df[field1])) * 1.2
                        print("plotting {} and {}".format(field0, field1))
                        g = sns.JointGrid(data=df,
                                          x=field0,
                                          y=field1,
                                          xlim = [0,xmax],
                                          ylim = [0,ymax],
                                          marginal_ticks=True)
                        # plot the outliers
                        g.ax_joint.scatter(
                            data=tempdf,
                            x=field0,
                            y=field1,
                            linewidth = 0,
                            c='#808080', marker='o',
                            s=2)
                        # plot the init data
                        g.ax_joint.scatter(
                            data=initdf,
                            x=field0,
                            y=field1,
                            c='r', marker='o',
                            zorder=10)
                        cax = g.figure.add_axes([.15, .55, .02, .2])

                        g.plot_joint(sns.histplot, discrete=(True, True),
                            #cmap="light:#03012d", cbar=True, cbar_ax=cax)
                            #pthresh = 0.0001,
                            #cmap="gist_yarg", cbar=True, cbar_ax=cax)
                            cmap=newcmp, cbar=True, cbar_ax=cax)

                        maxfield0 = max(df[field0])
                        maxfield1 = max(df[field1])

                        xbins=np.arange(0, maxfield0, 1)
                        _ = g.ax_marg_x.hist(df[field0], color="#000000", alpha=.6,
                                              bins=xbins, align="left")
                        ybins=np.arange(0, maxfield1, 1)
                        _ = g.ax_marg_y.hist(df[field1], color="#000000", alpha=.6,
                                              bins=ybins,
                                              orientation="horizontal", align="left")

                        fig = g.fig
                        pdf_pages.savefig(fig)
                        plt.close(g.fig)

rule plot_hypothesis_support:
    """
    Plots the hypothesis support of S1 or S2 as sister.
    """
    input:
        data = "odp_genome_mutation_analysis/sim_randomization/plottable_final/random_sim_final_plottable_{species}.txt",
        init = "odp_genome_mutation_analysis/sim_randomization/initialization/random_sim_init_plottable.txt"
    output:
        pdf = "odp_genome_mutation_analysis/figures/{spstr}_support_{species}-randomizations.pdf"
    params:
        species = lambda wildcards: wildcards.species
    run:
        import matplotlib.cm as cm
        from matplotlib import pyplot as plt
        import matplotlib
        matplotlib.rcParams['pdf.fonttype'] = 42
        matplotlib.rcParams['ps.fonttype'] = 42
        initdf = pd.read_csv(input.init, index_col = None, sep = "\t")
        df = pd.read_csv(input.data, index_col = None, sep = "\t")

        import seaborn as sns
        sns.set_theme(style="ticks")

        possible_vars = list(set(["_".join(x.split("_")[1::]) for x in df.columns]))
        plot_these = ["total_number_of_genes_in_FLGs",
                      "total_number_of_groupings",
                      "max_number_of_genes_in_grouping",
                      "max_number_of_genes_in_single_FLG"]

        plot_to_xlabel = {"total_number_of_genes_in_FLGs": "Genes in PI LGs",
                          "total_number_of_groupings": "Number of LG groupings",
                          "max_number_of_genes_in_grouping": "Genes in largest LG grouping",
                          "max_number_of_genes_in_single_FLG": "Genes in largest LG"
                         }

        for x in plot_these:
            if x not in possible_vars:
                raise IOError("{} was not in the input df".format(x))

        with PdfPages(output.pdf) as pdf_pages:
            for thisthing in plot_these:
                fig, ax = plt.subplots(3, 1, sharey = True, sharex = True)
                fig.suptitle("{}, {} randomized".format(thisthing, params.species), fontsize=8)
                fig.set_size_inches(5, 5)
                columns = ["{}_{}".format(x, thisthing) for x in ["hyp1", "hyp2", "hyp3"]]
                index = 0

                hyp1_init = initdf.iloc[0][columns[0]]
                hyp2_init = initdf.iloc[0][columns[1]]
                hyp3_init = initdf.iloc[0][columns[2]]
                xmax = int(max([hyp1_init, hyp2_init, hyp3_init,
                            max(df[columns[0]]),
                            max(df[columns[1]]),
                            max(df[columns[2]])
                          ]) * 1.2)
                ymax = max([len(df[x]) for x in columns])
                for thiscol in columns:
                    sns.histplot(df[thiscol], discrete = True,
                                 label=thiscol, color = "#000000",
                                      ax=ax[index])
                    ax[index].set_title(thiscol, fontsize = 6)
                    ax[index].ticklabel_format(axis='y', style='sci', scilimits=(0,0))
                    ax[index].tick_params(axis='both', which='major', labelsize=8)
                    ax[index].xaxis.label.set_size(8)
                    ax[index].yaxis.label.set_size(8)
                    sns.despine(offset=2, trim=False)
                    index += 1

                # set the plotting limits
                #ax[0].set_xlim([-1,xmax])
                #ax[1].set_xlim([-1,xmax])
                ylim = ax[0].get_ylim()[-1]
                ax[0].axvline(hyp1_init, 0, (ylim*0.75)/ylim, color = "#c44e52")
                ax[1].axvline(hyp2_init, 0, (ylim*0.75)/ylim, color = "#c44e52")
                ax[2].axvline(hyp3_init, 0, (ylim*0.75)/ylim, color = "#c44e52")

                # now set the names
                ax[0].set(ylabel="count\n{} sister".format(config["species1"]))
                ax[1].set(ylabel="count\n{} sister".format(config["species2"]))
                ax[2].set(ylabel="count\n{} sister".format(config["species3"]))

                # set the xlabel
                ax[2].set_xlabel(plot_to_xlabel[thisthing])
                plt.tight_layout()

                pdf_pages.savefig(fig)
                plt.close()
