"""
This script performs reciprocal-best protein searches, n-ways,
  then shows how many pairs are conserved between them.

The algorithm can use blastp or DIAMOND blast.
I tried implementing this for jackhmmer but it is painfully slow
 and the results don't seem much better than just blastp.
"""

from Bio import SeqIO
import copy
from itertools import groupby
from itertools import combinations
from itertools import permutations
import matplotlib
from matplotlib import pyplot as plt
from multiprocessing import Pool
import math
import networkx as nx
from operator import itemgetter
import pandas as pd
import numpy as np
import statistics
import sys
import odp_functions as odpf

configfile: "config.yaml"

config["tool"] = "odp_nway_rbh"

odpf.check_legality(config)

# check diamond_or_blastp
if "diamond_or_blastp" not in config:
    config["diamond_or_blastp"] = "blastp"
else:
    if config["diamond_or_blastp"] not in ["diamond", "blastp"]:
        raise IOError("diamond_or_blastp must be either 'diamond' or 'blastp'")

# make sure none of the sample names have underscores
for thissample in config["species"]:
    if "_" in thissample:
        raise IOError("Sample names can't have '_' char: {}".format(thissample))

# make sure there are at least 2 samples
if len(config["species"]) < 2:
    raise IOError("There must be at least 2 samples")
# make sure that nways is there
if not "nways" in config:
    raise IOError("you must specify nways in the config file. must be at least 2.")
# make sure that nways is greater than equal to 2
if config["nways"] < 2:
    raise IOError("nways must be at least 2")

# make sure that num species is gteq nways
if not len(config["species"]) >= config["nways"]:
    raise IOError("The number of species must be greater than or equal to nways")

# come up with all of the analyses
analyses_list = [list(sorted(x)) for x in config["analyses"]]
all_species = list(set([x for x in odpf.flatten(analyses_list)]))
print("Here is an example of the first few analyses: {}".format(analyses_list[0:3]))
print("There are {} possible combinations.".format(len(analyses_list)))

# make sure all of the species in the analyses are in the config
for entry in analyses_list:
    for thisspecies in entry:
        if thisspecies not in config["species"]:
            raise IOError ("You specified {} in the analyses, but it isn't defined in species".format(thisspecies))
# This is specifically for the trio odp
config["yaxisspecies"] = config["species"]

rule all:
    input:
        # find the reciprocal best hits
        [config["tool"] + "/RBH/{}_reciprocal_best_hits.tsv".format(
            "_".join(thisanalysis)) for thisanalysis in analyses_list],

def filter_fasta_chrom(chrom_file, input_fasta, output_fasta):
    """
    takes a chrom file, only keeps proteins in input_fasta from chrom file,
     saves those prots to output_fasta
    """
    keep_these = set()
    printed_already = set()
    with open(chrom_file, "r") as f:
        for line in f:
            line = line.strip()
            if line:
                splitd = line.split()
                keep_these.add(splitd[0])
    outhandle = open(output_fasta, "w")
    inhandle =  open(input_fasta, "r")
    for record in SeqIO.parse(inhandle, "fasta"):
        if record.id in keep_these and record.id not in printed_already:
            SeqIO.write(record, outhandle, "fasta")
            printed_already.add(record.id)
    inhandle.close()
    outhandle.close()

rule filter_prots_x:
    """
    Sometimes the prot file with have sequences that are not present in
     the chrom file. Make a prot file of only the proteins in the chrom file.
    """
    input:
        prots = lambda wildcards: config["species"][wildcards.xsample]["proteins"],
        chrom = lambda wildcards: config["species"][wildcards.xsample]["prot_to_loc"]
    output:
        pep = config["tool"] + "/db/xaxis/{xsample}_prots.pep"
    threads: 1
    run:
        filter_fasta_chrom(input.chrom, input.prots, output.pep)

rule filter_prots_y:
    """
    Sometimes the prot file with have sequences that are not present in
     the chrom file. Make a prot file of only the proteins in the chrom file.
    """
    input:
        prots = lambda wildcards: config["yaxisspecies"][wildcards.ysample]["proteins"],
        chrom = lambda wildcards: config["yaxisspecies"][wildcards.ysample]["prot_to_loc"]
    output:
        pep = config["tool"] + "/db/yaxis/{ysample}_prots.pep"
    threads: 1
    run:
        filter_fasta_chrom(input.chrom, input.prots, output.pep)


rule make_diamond_and_blast_db_x:
    input:
        pep = ancient(config["tool"] + "/db/xaxis/{xsample}_prots.pep")
    output:
        dmnd = config["tool"] + "/db/xaxis/dmnd/{xsample}_prots.dmnd",
        pdb  = config["tool"] + "/db/xaxis/{xsample}_prots.pep.pdb"
    threads: workflow.cores - 1
    shell:
        """
        diamond makedb --in {input.pep} --db {output.dmnd}
        makeblastdb -in {input.pep} -dbtype prot
        """

rule make_diamond_and_blast_db_y:
    input:
        pep = ancient(config["tool"] + "/db/yaxis/{ysample}_prots.pep")
    output:
        dmnd = config["tool"] + "/db/yaxis/dmnd/{ysample}_prots.dmnd",
        pep =  config["tool"] + "/db/yaxis/{ysample}_prots.pep.pdb"
    threads: workflow.cores - 1
    shell:
        """
        diamond makedb --in {input.pep} --db {output.dmnd}
        makeblastdb -in {input.pep} -dbtype prot
        """

rule diamond_blast_x_to_y:
    input:
        xpep  = ancient(config["tool"] + "/db/xaxis/{xsample}_prots.pep"),
        ydmnd = ancient(config["tool"] + "/db/yaxis/dmnd/{ysample}_prots.dmnd"),
        ypep  = ancient(config["tool"] + "/db/yaxis/{ysample}_prots.pep"),
        ypdb  = ancient(config["tool"] + "/db/yaxis/{ysample}_prots.pep.pdb")
    output:
        blastp = config["tool"] + "/blastp_results/xtoy/{xsample}_against_{ysample}.blastp",
    threads: int(workflow.cores/2) if (config["search_method"] == "jackhmmer") else (workflow.cores - 1)
    params:
        search_method = config["search_method"],
    priority: 1
    shell:
        """
        if [ "{params.search_method}" = "blastp" ]; then
            blastp -query {input.xpep} -db {input.ypep} \
              -num_threads {threads} -evalue 1E-5 -outfmt 6 > {output.blastp}
        elif [ "{params.search_method}" = "diamond" ]; then
            diamond blastp --query {input.xpep} --db {input.ydmnd} \
              --threads {threads} --evalue 1E-5 --outfmt 6 --out {output.blastp}
        elif [ "{params.search_method}" = "jackhmmer" ]; then
            jackhmmer --cpu {threads} --noali --tblout {output.blastp} \
              {input.xpep} {input.ypep} > /dev/null
        fi
        """

rule diamond_blast_y_to_x:
    input:
        ypep  = ancient(config["tool"] + "/db/yaxis/{ysample}_prots.pep"),
        xdmnd = ancient(config["tool"] + "/db/xaxis/dmnd/{xsample}_prots.dmnd"),
        xpep  = ancient(config["tool"] + "/db/xaxis/{xsample}_prots.pep"),
        xpdb  = ancient(config["tool"] + "/db/xaxis/{xsample}_prots.pep.pdb")
    output:
        blastp = config["tool"] + "/blastp_results/ytox/{ysample}_against_{xsample}.blastp",
    threads: int(workflow.cores/2) if (config["search_method"] == "jackhmmer") else (workflow.cores - 1)
    params:
        search_method = config["search_method"]
    priority: 1
    shell:
        """
        if [ "{params.search_method}" = "blastp" ]; then
            blastp -query {input.ypep} -db {input.xpep} \
              -num_threads {threads} -evalue 1E-5 -outfmt 6 > {output.blastp}
        elif [ "{params.search_method}" = "diamond" ]; then
            diamond blastp --query {input.ypep} --db {input.xdmnd} \
              --threads {threads} --evalue 1E-5 --outfmt 6 --out {output.blastp}
        elif [ "{params.search_method}" = "jackhmmer" ]; then
            jackhmmer --cpu {threads} --noali --tblout {output.blastp} \
              {input.ypep} {input.xpep} > /dev/null
        fi
        """

rule reciprocal_best_hits:
    """
    finds the reciprocal best hits.
    reports it in the form of the blastp results from x -> y search
    """
    input:
        xtoyblastp = config["tool"] + "/blastp_results/xtoy/{xsample}_against_{ysample}.blastp",
        ytoxblastp = config["tool"] + "/blastp_results/ytox/{ysample}_against_{xsample}.blastp"
    output:
        xtoyblastp = config["tool"] + "/blastp_results/reciprocal_best/{xsample}_and_{ysample}_recip.temp.blastp",
    threads: 1
    run:
        odpf.reciprocal_best_hits_blastp_or_diamond_blastp(
            input.xtoyblastp, input.ytoxblastp, output.xtoyblastp)

def get_component_size_dict(G):
    """
    Prints out a dictionary of the component sizes of the graph.
    G is the graph.

    keys are the sizes of the components.
    values are the number of components of that size
    """
    component_size = {}
    for thisentry in list(nx.connected_components(G)):
        if len(thisentry) not in component_size:
            component_size[len(thisentry)] = 0
        component_size[len(thisentry)] += 1
    print(component_size)

rule n_ways_reciprocal_best:
    """
    Gets reciprocal best hits from 3 or more samples
    For a protein to be retained, it must be a reciprocal-best hit in three samples.

              A      B
             / \    /|\
            B___C  A-+-C , et cetera
                    \|/
                     D

    The output of this rule is a yaml file with admissible proteins from each sample
    """
    input:
        xtoyblastp =[config["tool"] + "/blastp_results/reciprocal_best/{}_and_{}_recip.temp.blastp".format(x[0], x[1])
            for x in permutations(
               ["{{sample{}}}".format(i)
                for i in range(config["nways"])], config["nways"])],
        chrom = lambda wildcards: [config["species"][x]["prot_to_loc"]
                    for x in all_species]
    output:
        acceptable_prots =   config["tool"] + "/blastp_results/reciprocal_best/{}_acceptable_prots.txt".format(
            "_".join(["{{sample{}}}".format(i) for i in range(config["nways"])])),
        blast_network      = config["tool"] + "/blastp_results/reciprocal_best/{}_edges.txt".format(
            "_".join(["{{sample{}}}".format(i) for i in range(config["nways"])])),
        RBH                = config["tool"] + "/RBH/{}_reciprocal_best_hits.tsv".format(
            "_".join(["{{sample{}}}".format(i) for i in range(config["nways"])]))
    threads: 1
    params:
        num_ways = config["nways"]
    run:
        # prot to group
        prot_to_group = {}
        if "prot_to_group" in config:
            if os.path.exists(config["prot_to_group"]):
                with open(config["prot_to_group"], "r") as f:
                    for line in f:
                        line = line.strip()
                        fields = line.split("\t")
                        prot_to_group[fields[0]] = fields[1]
        #print(prot_to_group)
        species_string = output.acceptable_prots.split("/")[-1].replace("_acceptable_prots.txt", "")
        all_species = [x for x in species_string.split("_")]
        combos = list(combinations(all_species, 2))
        blastfiles = [[config["tool"] + "/blastp_results/reciprocal_best/{}_and_{}_recip.temp.blastp".format(x[0], x[1]),
             x[0], x[1]] for x in combos]
        gene_to_species = {}
        gene_list = set()

        # get the chrom files
        chrom_dicts = {}
        for thisspecies in all_species:
            if not os.path.exists(config["species"][thisspecies]["prot_to_loc"]):
                raise IOError("This chrom file doesn't exist: {}".format(
                    config["species"][thisspecies]["prot_to_loc"]))
            chrom_dicts[thisspecies] = pd.read_csv(
                config["species"][thisspecies]["prot_to_loc"],
                header=None, sep = "\t")
            chrom_dicts[thisspecies].columns = ["prot",
                "scaf", "direction", "start", "stop"]

        # initialize the graph
        G = nx.Graph()
        checked_names = set()
        for analysis in blastfiles:
            print(analysis)
            thisfile = analysis[0]
            a = analysis[1]
            b = analysis[2]
            with open(thisfile, "r") as f:
                for line in f:
                    line = line.strip()
                    if line:
                        splitb = line.split("\t")
                        agene = "{}_{}".format(a, splitb[0])
                        bgene = "{}_{}".format(b, splitb[1])
                        evalue = float(splitb[-2])
                        bitscore = float(splitb[-1])
                        if a not in checked_names:
                            if agene in gene_list:
                                raise IOError("""We saw a gene twice. {}.
                                This means that two species have the same prot ids.""".format(agene))
                        gene_list.add(agene)
                        if b not in checked_names:
                            if bgene in gene_list:
                                raise IOError("""We saw a gene twice. {}.
                                This means that two species have the same prot ids.""".format(bgene))
                        gene_list.add(bgene)
                        gene_to_species[agene] = a
                        gene_to_species[bgene] = b
                        #add these since we've added the genes already
                        checked_names.add(a)
                        checked_names.add(b)
                        # now add the edge
                        G.add_edge(agene, bgene, weight = bitscore)
        remnodes = set()
        #get rid of things that couldn't possibly be an n-way best
        for thisentry in list(nx.connected_components(G)):
            if len(thisentry) < len(all_species):
                for node in thisentry:
                    remnodes.add(node)
        for node in remnodes:
            G.remove_node(node)
        remnodes.clear()

        # now get rid of nodes that don't have the correct degree
        #  to be n-connected
        for thisnode in G.nodes:
            if G.degree[thisnode] != (len(all_species) - 1):
                remnodes.add(thisnode)
        for node in remnodes:
            G.remove_node(node)
        remnodes.clear()
        # now get the n-connected components
        nwaybest = []
        for thisentry in list(nx.connected_components(G)):
            if len(thisentry) == len(all_species):
                nwaybest.append(thisentry)
            else:
                for node in thisentry:
                    remnodes.add(node)
        #cleanup the graph
        for node in remnodes:
            G.remove_node(node)
        remnodes.clear()
        # print out the graph
        uniquenodes = set()
        with open(output.blast_network, "w") as f:
            for thisedge in G.edges:
                agene = "_".join(thisedge[0].split("_")[1::])
                bgene = "_".join(thisedge[1].split("_")[1::])
                print("{}\t{}".format(agene, bgene), file = f)
                uniquenodes.add(thisedge[0])
                uniquenodes.add(thisedge[1])
        with open(output.acceptable_prots, "w") as f:
            for thisnode in uniquenodes:
                thisgene = "_".join(thisnode.split("_")[1::])
                print(thisgene, file = f)
        # print out the list of genes
        CCs = []
        for thisentry in list(nx.connected_components(G)):
            ccdict = {"RBH": "RBH{}way_{}_{}".format(
                len(all_species), "_".join(all_species), len(CCs)+1)}
            for node in thisentry:
                thisgene = "_".join(node.split("_")[1::])
                ccdict["{}_gene".format(gene_to_species[node])] = thisgene
            CCs.append(ccdict)
        genesdf = pd.DataFrame(CCs)
        genesdf["gene_group"] = "None"
        print(genesdf)

        # now add the other info
        for thisspecies in all_species:
            genesdf["{}_scaf".format(thisspecies)] = genesdf[
                "{}_gene".format(thisspecies)].map(
                    dict(zip(chrom_dicts[thisspecies].prot,
                             chrom_dicts[thisspecies].scaf)) )
            genesdf["{}_pos".format(thisspecies)] = genesdf[
                "{}_gene".format(thisspecies)].map(
                    dict(zip(chrom_dicts[thisspecies].prot,
                             chrom_dicts[thisspecies].start)))

        # add the gene_group info
        for index, row in genesdf.iterrows():
            for thisspecies in all_species:
                this_gene = row["{}_gene".format(thisspecies)]
                if this_gene in prot_to_group:
                    genesdf.loc[index, "gene_group"] = prot_to_group[this_gene]
        genesdf.to_csv(output.RBH, sep="\t")
