"""
This script takes a RBH file from odp_trio, and performs an HMM search against
all of the other species in the config file.

The output of this is an RBH .tsv file, with or without a group column,
 that has the RBHs and their orthologs.
"""

import ast
from Bio import SeqIO
from Bio import SeqRecord
from Bio import Seq
from itertools import groupby
from itertools import product
import math
import numpy as np
import odp_functions as OdpF
from operator import itemgetter
import pandas as pd
import statistics

configfile: "config.yaml"

config["tool"] = "odp_RBH_to_HMM"

OdpF.check_legality(config)

if not "RBH_file" in config:
    raise IOError("You must specify 'RBH_file' in config, and it must be named just like the output of odp_trio: {species1}_{species_N}_reciprocal_best_hits.tsv")

if not "_reciprocal_best_hits.tsv" in config["RBH_file"]:
    raise IOError("The 'RBH_file' in config must be named just like the output of odp_trio: {species1}_{species_N}_reciprocal_best_hits.tsv")

if not "species" in config:
    raise IOError("You must specify all of the species that will be involved in this analysis in the config.yaml file.")

# make sure none of the sample names have underscores
for thissample in config["species"]:
    if "_" in thissample:
        raise IOError("Sample names can't have '_' char: {}".format(thissample))

# come up with the species in the RBH
myfile = config["RBH_file"]
species_string = myfile.split("/")[-1].replace("_reciprocal_best_hits.tsv", "")
RBH_species = list(sorted(species_string.split("_")))
print("RBH_species")
print(RBH_species)

if len(RBH_species) < 3:
    raise IOError("There must be at least two species in the RBH file.")

# come up with other species to perform the HMM search against
other_species = [x for x in config["species"] if x not in RBH_species]
print()
print("other_species")
print(other_species)

if len(RBH_species) < 1:
    raise IOError("There must be at least one species to search against.")

config["nways"] = len(RBH_species)

# come up with number of RBHs
newstring = "RBH{}way_{}".format(len(RBH_species), "_".join(sorted(RBH_species)))
testdf = pd.read_csv(config["RBH_file"], sep = "\t", index_col = 0)
RBH_entries = list(testdf["RBH"])

rule all:
    input:
        #expand(config["tool"] + "/fasta/unaligned/{RBH}.fasta",
        #       RBH = RBH_entries),
        #expand(config["tool"] + "/hmm/hmms/{RBH}.hmm",
        #       RBH = RBH_entries),
        #expand(config["tool"] + "/hmm/searches/{other_species}/{RBH}_against_{other_species}.tsv",
        #       other_species = other_species, RBH = RBH_entries),
        expand(config["tool"] + "/hmm/searches_agg/{other_species}_hmm_results.sorted.tsv",
               other_species = other_species, RBH = RBH_entries),
        #expand("hmm/searches_agg_best/{species}_hmm_best.tsv",
        #       species = config["yaxisspecies"]),
        config["tool"] + "/output/" + species_string + "_RBHhmm_plus_other_species.RBH"

rule generate_fasta_of_each_RBH:
    input:
        RBH = config["RBH_file"],
        proteins = lambda wildcards: [config["species"][x]["proteins"]
                    for x in RBH_species]
    output:
        MBH_fasta = expand(config["tool"] + "/fasta/unaligned/{RBH}.fasta",
                           RBH = RBH_entries)
    threads: 1
    run:
        print(" - Reading the dataframe of RBHs.")
        df = pd.read_csv(input.RBH, index_col = 0, sep = "\t")

        # make a dict of gene_to_RBH
        print(" - Making a dict of gene_to_RBH")
        species_to_gene_to_RBH = {}
        for index, row in df.iterrows():
            thisRBH = row["RBH"]
            for this_species in RBH_species:
                if this_species not in species_to_gene_to_RBH:
                    species_to_gene_to_RBH[this_species] = {}
                genecol = "{}_gene".format(this_species)
                species_to_gene_to_RBH[this_species][row[genecol]] = thisRBH

        # now make a dict of RBH_to_fasta_records
        print(" - Making a dict of RBH_to_fasta_records.")
        RBH_to_records = {}
        for this_species in RBH_species:
            inhandle = open(config["species"][this_species]["proteins"], "r")
            for record in SeqIO.parse(inhandle, "fasta"):
                if record.id in species_to_gene_to_RBH[this_species]:
                    thisRBH = species_to_gene_to_RBH[this_species][record.id]
                    record.name = record.id
                    newid = "{}_{}".format(thisRBH, this_species)
                    record.id = newid
                    if thisRBH not in RBH_to_records:
                        RBH_to_records[thisRBH] = []
                    RBH_to_records[thisRBH].append(record)

        # make sure that all entries have as many sequences as species
        print(" - Verifying that the records are all complete.")
        for thisRBH in RBH_to_records:
            if len(RBH_to_records[thisRBH]) != len(RBH_species):
                raise IOError("{} only has {} genes".format(
                    thisRBH, len(RBH_to_records[thisRBH])))

        # print out all of the records to fasta files
        print(" - Printing out the FASTA records.")
        for thisRBH in RBH_to_records:
            outfile = config["tool"] + "/fasta/unaligned/{}.fasta".format(thisRBH)
            with open(outfile, "w") as output_handle:
                for thisrec in RBH_to_records[thisRBH]:
                    SeqIO.write(thisrec, output_handle, "fasta")

rule align_fasta_of_each_group:
    input:
        MBH_fasta = config["tool"] + "/fasta/unaligned/{RBH}.fasta"
    output:
        aligned =   config["tool"] + "/fasta/aligned/{RBH}.aligned.fasta",
    threads: 1
    shell:
        """
        mafft --localpair --maxiterate 1000 {input.MBH_fasta} > {output.aligned}
        """

rule make_hmm:
    input:
        aligned = config["tool"] + "/fasta/aligned/{RBH}.aligned.fasta"
    output:
        hmm     = config["tool"] + "/hmm/hmms/{RBH}.hmm"
    threads: 1
    shell:
        """
        hmmbuild {output.hmm} {input.aligned}
        """

rule hmm_search_against_genome:
    input:
        proteins = lambda wildcards: config["species"][wildcards.other_species]["proteins"],
        hmm = config["tool"] + "/hmm/hmms/{RBH}.hmm"
    output:
        tsv = config["tool"] + "/hmm/searches/{other_species}/{RBH}_against_{other_species}.tsv"
    threads: 2
    shell:
        """
        hmmsearch --tblout {output.tsv} \
          --cpu {threads} \
          --noali \
          --notextw \
          {input.hmm} \
          {input.proteins}
        """

rule aggregate_hmm_results_by_species:
    """
    The header fields are:
    # target name        accession  query name                         accession    E-value  score  bias   E-value  score  bias   exp reg clu  ov env dom rep inc description of target

    the headers for blastp outfmt 6 are:
      qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore
    """
    input:
        tsv = expand(config["tool"] + "/hmm/searches/{{other_species}}/{RBH}_against_{{other_species}}.tsv",
                     RBH = RBH_entries)
    output:
        tsv =        config["tool"] + "/hmm/searches_agg/{other_species}_hmm_results.tsv"
    params:
        this_species = lambda wildcards: wildcards.other_species
    threads: 1
    run:
        entries = []
        for thisfile in input.tsv:
            with open(thisfile, "r") as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith("#"):
                        fields = line.split()
                        thisentry = {"qseqid": fields[2].replace(".aligned", ""),
                                     "sseqid": fields[0],
                                     "pident": 50.0,
                                     "length": 50.0,
                                     "mismatch": 0,
                                     "gapopen": 0,
                                     "qstart": 0,
                                     "qend": 0,
                                     "sstart": 0,
                                     "send": 0,
                                     "evalue": float(fields[4]),
                                     "bitscore": float(fields[5]) }
                        entries.append(thisentry)
        df = pd.DataFrame(entries)
        df.to_csv(output.tsv, sep="\t", index = False, header = False)

rule sort_the_collated_hmm_results:
    input:
        tsv =        config["tool"] + "/hmm/searches_agg/{other_species}_hmm_results.tsv"
    output:
        tsv =        config["tool"] + "/hmm/searches_agg/{other_species}_hmm_results.sorted.tsv"
    params:
        this_species = lambda wildcards: wildcards.other_species
    shell:
        """
        cat {input.tsv} | sort -k12,12nr > {output.tsv}
        """

rule best_gene_for_each_hmm:
    """
    finds the best hmm for each gene
    """
    input:
        tsv = config["tool"] + "/hmm/searches_agg/{other_species}_hmm_results.sorted.tsv"
    output:
        tsv = config["tool"] + "/hmm/searches_agg_best/{other_species}_hmm_best.tsv"
    threads: 1
    run:
        df = pd.read_csv(input.tsv, header = None, sep = "\t")
        df.columns = ["qseqid", "sseqid", "pident", "length", "mismatch",
                      "gapopen", "qstart", "qend", "sstart", "send",
                      "evalue", "bitscore"]
        df = df.sort_values(["bitscore"], ascending = [False])
        df = df.drop_duplicates(subset = ["sseqid"], keep = "first")
        df = df.drop_duplicates(subset = ["qseqid"], keep = "first")
        df = df.reset_index(drop=True)
        df.to_csv(output.tsv, header = False, index = False, sep="\t")

rule collate_best_hits_into_best_hits_file:
    """
    put the HMM best hits info into a single file for all species.
    we need a {}_gene, {}_scaf, and {}_pos column for each new species we put in.
    """
    input:
        RBH_file = config["RBH_file"],
        best_hits_files = expand(config["tool"] + "/hmm/searches_agg_best/{other_species}_hmm_best.tsv",
                                 other_species = other_species),
        chrom = lambda wildcards: [config["species"][x]["prot_to_loc"] for x in
                                   other_species]
    output:
        RBH = config["tool"] + "/output/" + species_string + "_RBHhmm_plus_other_species.RBH"
    run:
        RBH = pd.read_csv(input.RBH_file, header = 0, index_col = 0, sep = "\t")
        for thisspecies in other_species:
            thischrom = config["species"][thisspecies]["prot_to_loc"]
            species_gene_to_chrom = {}
            species_gene_to_pos = {}
            with open(thischrom, "r") as f:
                for line in f:
                    line = line.strip()
                    if line:
                        fields = line.split()
                        species_gene_to_chrom[fields[0]] = fields[1]
                        species_gene_to_pos[fields[0]] = int(fields[3])
            readthis = config["tool"] + "/hmm/searches_agg_best/{}_hmm_best.tsv".format(thisspecies)
            species_RBH = pd.read_csv(readthis, header = None, sep = "\t")
            species_RBH.columns = ["qseqid", "sseqid", "pident", "length", "mismatch",
                                   "gapopen", "qstart", "qend", "sstart", "send",
                                   "evalue", "bitscore"]


            RBH["{}_gene".format(thisspecies)] = RBH["RBH"].map(
                        dict(zip(species_RBH["qseqid"],
                                 species_RBH["sseqid"])) )

            RBH["{}_scaf".format(thisspecies)] = RBH[
                "{}_gene".format(thisspecies)].map(species_gene_to_chrom)

            RBH["{}_pos".format( thisspecies)] = RBH[
                "{}_gene".format(thisspecies)].map(species_gene_to_pos)

        RBH_sorted = list(sorted([x for x in RBH.columns if x.split("_")[0] in RBH_species]))
        other_sorted = list(sorted([x for x in RBH.columns if x.split("_")[0] in other_species]))
        annot_col = list(sorted([x for x in RBH.columns if x not in ["RBH"] + RBH_sorted + other_sorted]))
        sorted_cols = ["RBH"] + annot_col + RBH_sorted + other_sorted
        RBH = RBH.reindex(sorted_cols, axis=1)
        RBH = RBH.fillna(value = "None")
        RBH.to_csv(output.RBH,  sep="\t", header = True, index = False)


#rule best_gene_for_each_hmm_LEGACY:
#    """
#    finds the best hmm for each gene
#    """
#    input:
#        tsv = config["tool"] + "/hmm/searches_agg/{other_species}_hmm_results.sorted.tsv"
#        chrom = lambda wildcards: config["xaxisspecies"][wildcards.species]["prot_to_loc"],
#        RBH = "RBH/reciprocal_best_hits.tsv"
#    output:
#        tsv = "hmm/searches_agg_best/{species}_hmm_best.tsv",
#        RBHinfo = "hmm/RBH_plus_HMM_agg_best/{species}_hmm_chrom_info.tsv",
#        groupby = "hmm/RBH_plus_HMM_agg_best/{species}_hmm_chrom_info.groupby.tsv"
#    params:
#        species = lambda wildcards: wildcards.species
#    threads: 1
#    run:
#        species_gene_to_chrom = {}
#        species_gene_to_pos = {}
#        with open(input.chrom, "r") as f:
#            for line in f:
#                line = line.strip()
#                if line:
#                    fields = line.split()
#                    species_gene_to_chrom[fields[0]] = fields[1]
#                    species_gene_to_pos[fields[0]] = int(fields[3])
#        df = pd.read_csv(input.tsv, index_col = 0, sep = "\t")
#        df = df.sort_values(["sseqid", "evalue"], ascending=[True, True])
#        df = df.drop_duplicates(subset = ["sseqid"])
#        df = df.sort_values(["qseqid", "evalue"], ascending=[True, True])
#        df = df.drop_duplicates(subset = ["qseqid"])
#        df = df.reset_index(drop=True)
#        df.to_csv(output.tsv, header = False, index = False, sep="\t")
#        df = df.iloc[:, 0:2]
#        df.columns = ["RBH", params.species]
#        RBH = pd.read_csv(input.RBH, index_col = 0, sep = "\t")
#        RBH["{}_gene".format(params.species)] = RBH["RBH"].map(
#                    dict(zip(df["RBH"],
#                             df[params.species])) )
#        RBH["{}_scaf".format(params.species)] = RBH[
#            "{}_gene".format(params.species)].map(
#            species_gene_to_chrom)
#        RBH["{}_pos".format(params.species)] = RBH[
#            "{}_gene".format(params.species)].map(
#            species_gene_to_pos)
#        RBH.to_csv(output.RBHinfo,  sep="\t")
#
#        groupbycols = [x for x in RBH.columns if "_scaf" in x]
#        grouped_multiple = RBH.groupby(groupbycols).agg(list).reset_index()
#        # get the size
#        grouped_multiple["count"] = grouped_multiple.RBH.str.len()
#        grouped_multiple.to_csv(output.groupby,  sep="\t")
